"""
Pipeline Principal de An√°lise de Readmiss√£o Hospitalar Diab√©tica

Este script orquestra a execu√ß√£o completa do pipeline de Machine Learning, incluindo:
1. An√°lise Explorat√≥ria de Dados (EDA) - Compreens√£o inicial dos padr√µes
2. Limpeza e Pr√©-processamento - Tratamento de dados faltantes e inconsist√™ncias  
3. Engenharia de Features - Transforma√ß√£o e prepara√ß√£o para modelagem
4. Treinamento de Modelos ML - Regress√£o Log√≠stica e Random Forest
5. Avalia√ß√£o e Valida√ß√£o - M√©tricas de performance e visualiza√ß√µes
6. Gera√ß√£o de Relat√≥rios - Documenta√ß√£o completa dos resultados

Modos de Execu√ß√£o:
    python main_pipeline.py                # Pipeline completo com otimiza√ß√µes
    python main_pipeline.py --demo        # Demonstra√ß√£o r√°pida (apenas modelagem)
    python main_pipeline.py --fast        # Pipeline completo sem otimiza√ß√£o de hiperpar√¢metros

Autor: Thalles Felipe Rodrigues de Almeida Santos
Projeto: Predi√ß√£o de Readmiss√£o Hospitalar em Pacientes com Diabetes Usando Aprendizado de M√°quina
Institui√ß√£o: Universidade Federal de Ouro Preto (UFOP)
Disciplina: Intelig√™ncia Artificial
Professor: Jadson Castro Gertrudes
Data: Agosto 2025
"""

import os
import sys
import time
import traceback
from datetime import datetime

# Adicionar diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importa√ß√µes dos m√≥dulos do projeto
from src.exploratory_analysis import ExploratoryDataAnalysis
from src.data_cleaning import DataCleaner
from src.feature_engineering import FeatureEngineer
from src.logistic_regression_model import LogisticRegressionModel
from src.config import (
    RAW_DATA_FILE, CLEAN_DATA_FILE, PROCESSED_DATA_FILE,
    MODELS_DIR, RESULTS_DIR, DATA_DIR
)


def ensure_directories():
    """Garante que todos os diret√≥rios necess√°rios existam"""
    directories = [DATA_DIR, RESULTS_DIR, MODELS_DIR]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"‚úì Diret√≥rio verificado: {directory}")


def print_pipeline_header():
    """Imprime cabe√ßalho do pipeline"""
    print("üè•" + "="*70 + "üè•")
    print("    PIPELINE COMPLETO DE AN√ÅLISE DE READMISS√ÉO HOSPITALAR DIAB√âTICA")
    print("    Projeto: Predi√ß√£o de Readmiss√£o Hospitalar em Pacientes com Diabetes Usando Aprendizado de M√°quina")
    print("    Dataset: UCI Diabetes 130-US hospitals (1999-2008)")
    print("    Objetivo: Predizer readmiss√£o em < 30 dias")
    print("üè•" + "="*70 + "üè•")


def print_stage_header(stage_num, stage_name, description=""):
    """Imprime cabe√ßalho padronizado para cada etapa"""
    print(f"\n{'='*20} ETAPA {stage_num}: {stage_name.upper()} {'='*20}")
    if description:
        print(f"Objetivo: {description}")
    print("=" * (42 + len(stage_name)))


def run_exploratory_analysis():
    """Executa an√°lise explorat√≥ria dos dados"""
    print_stage_header(1, "An√°lise Explorat√≥ria", 
                      "Compreens√£o inicial dos dados, identifica√ß√£o de padr√µes e problemas")
    
    try:
        eda = ExploratoryDataAnalysis(RAW_DATA_FILE)
        df_analyzed = eda.run_complete_analysis()
        
        print(f"‚úÖ An√°lise explorat√≥ria conclu√≠da!")
        print(f"   üìä Dataset: {df_analyzed.shape[0]:,} registros, {df_analyzed.shape[1]} colunas")
        print(f"   üìÅ Relat√≥rios gerados em: {RESULTS_DIR}")
        
        return df_analyzed
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise explorat√≥ria: {e}")
        raise


def run_data_cleaning():
    """Executa limpeza e pr√©-processamento dos dados"""
    print_stage_header(2, "Limpeza dos Dados", 
                      "Tratamento de dados faltantes, remo√ß√£o de inconsist√™ncias")
    
    try:
        cleaner = DataCleaner(RAW_DATA_FILE)
        df_clean = cleaner.clean_data(CLEAN_DATA_FILE)
        
        # Mostrar resumo da limpeza
        cleaner.get_cleaning_summary()
        
        # Obter estat√≠sticas diretamente dos dados
        original_records = cleaner.cleaning_stats.get('original_records', 'N/A')
        final_records = len(df_clean) if df_clean is not None else 0
        removed_records = (original_records - final_records) if isinstance(original_records, int) else 'N/A'
        
        print(f"‚úÖ Limpeza dos dados conclu√≠da!")
        print(f"   üìä Registros originais: {original_records:,}" if isinstance(original_records, int) else f"   üìä Registros originais: {original_records}")
        print(f"   üìä Registros finais: {final_records:,}")
        print(f"   üóëÔ∏è Registros removidos: {removed_records:,}" if isinstance(removed_records, int) else f"   üóëÔ∏è Registros removidos: {removed_records}")
        print(f"   üíæ Dados limpos salvos em: {CLEAN_DATA_FILE}")
        
        return df_clean
        
    except Exception as e:
        print(f"‚ùå Erro na limpeza dos dados: {e}")
        raise


def run_feature_engineering():
    """Executa engenharia de features e prepara√ß√£o para modelagem"""
    print_stage_header(3, "Engenharia de Features", 
                      "Transforma√ß√£o e prepara√ß√£o final dos dados para modelagem")
    
    try:
        engineer = FeatureEngineer(CLEAN_DATA_FILE)
        
        # Processar features e obter conjuntos de treino/teste
        X_train, X_test, y_train, y_test = engineer.process_features(PROCESSED_DATA_FILE)
        
        # Salvar datasets processados
        engineer.save_processed_datasets()
        
        # Obter relat√≥rio de processamento
        report = engineer.get_processing_report()
        
        print(f"‚úÖ Engenharia de features conclu√≠da!")
        print(f"   üéØ Conjunto de treino: {X_train.shape[0]:,} amostras, {X_train.shape[1]} features")
        print(f"   üéØ Conjunto de teste: {X_test.shape[0]:,} amostras, {X_test.shape[1]} features")
        print(f"   üìä Taxa de readmiss√£o (treino): {y_train.mean():.1%}")
        print(f"   üìä Taxa de readmiss√£o (teste): {y_test.mean():.1%}")
        print(f"   üíæ Datasets salvos em: {DATA_DIR}")
        
        return X_train, X_test, y_train, y_test
        
    except Exception as e:
        print(f"‚ùå Erro na engenharia de features: {e}")
        raise


def run_machine_learning_models(fast_mode=False, advanced_analysis=True):
    """Executa treinamento e avalia√ß√£o de modelos de Machine Learning com an√°lises avan√ßadas"""
    print_stage_header(4, "Modelagem de Machine Learning Avan√ßada", 
                      "Treinamento, valida√ß√£o robusta e an√°lise avan√ßada de features")
    
    if advanced_analysis:
        print("‚ú® MODO AVAN√áADO ATIVADO:")
        print("   üî¨ Valida√ß√£o Cruzada Aninhada")
        print("   üß¨ An√°lise Avan√ßada de Features")
        print("   üé® Dashboard Interativo")
        print("   üìã Relat√≥rios Detalhados")
        print("=" * 70)
    
    trained_models = {}
    
    try:
        # 1. Regress√£o Log√≠stica
        print("ü§ñ Inicializando Regress√£o Log√≠stica...")
        lr_model = LogisticRegressionModel()
        
        # Executar pipeline completo do modelo (com ou sem otimiza√ß√£o)
        lr_success = lr_model.run_complete_pipeline(
            tune_hyperparams=not fast_mode,    # Otimizar hiperpar√¢metros apenas se n√£o estiver em modo r√°pido
            optimize_threshold=True            # Sempre otimizar limiar de decis√£o
        )
        
        if lr_success:
            trained_models['logistic_regression'] = lr_model
            print(f"‚úÖ Regress√£o Log√≠stica executada com sucesso!")
            
            # Mostrar m√©tricas principais
            if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
                metrics = lr_model.evaluation_results
                print(f"   üìà Accuracy: {metrics.get('accuracy', 0):.1%}")
                print(f"   üìà Precision: {metrics.get('precision', 0):.1%}")
                print(f"   üìà Recall: {metrics.get('recall', 0):.1%}")
                print(f"   üìà F1-Score: {metrics.get('f1', 0):.1%}")
                print(f"   üìà ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
            
        else:
            print(f"‚ùå Erro na execu√ß√£o da Regress√£o Log√≠stica")
        
        # 2. Random Forest com An√°lises Avan√ßadas
        print("\nüå≤ Inicializando Random Forest Avan√ßado...")
        
        try:
            from src.random_forest_model import RandomForestModel
            
            rf_model = RandomForestModel()
            
            if fast_mode:
                print("‚ö° Modo r√°pido: configura√ß√µes otimizadas sem busca avan√ßada")
                # Configurar para demo r√°pida
                rf_model.model_config.update({
                    'n_estimators': 200,
                    'max_depth': 12,
                    'min_samples_split': 8,
                    'min_samples_leaf': 3
                })
                rf_success = rf_model.run_complete_pipeline(
                    tune_hyperparams=False,
                    optimize_threshold=True,
                    cv_folds=3
                )
            else:
                print("üöÄ Executando pipeline completo com an√°lises avan√ßadas...")
                rf_success = rf_model.run_complete_pipeline(
                    tune_hyperparams=True,
                    method='random_search',
                    optimize_threshold=True
                )
            
            if rf_success:
                trained_models['random_forest'] = rf_model
                print(f"‚úÖ Random Forest Avan√ßado executado com sucesso!")
                print(f"   üìà Accuracy: {rf_model.metrics['accuracy']:.1%}")
                print(f"   üìà Precision: {rf_model.metrics['precision']:.1%}")
                print(f"   üìà Recall: {rf_model.metrics['recall']:.1%}")
                print(f"   üìà F1-Score: {rf_model.metrics['f1']:.1%}")
                print(f"   üìà ROC-AUC: {rf_model.metrics['roc_auc']:.3f}")
                if rf_model.oob_score:
                    print(f"   üìà OOB Score: {rf_model.oob_score:.3f}")
                
                # ‚ú® DESTACAR RESULTADOS DAS AN√ÅLISES AVAN√áADAS ‚ú®
                if advanced_analysis and not fast_mode:
                    print(f"\nüî¨ RESULTADOS DAS AN√ÅLISES AVAN√áADAS:")
                    
                    # Valida√ß√£o aninhada
                    if 'nested_cv' in rf_model.validation_results:
                        nested_score = rf_model.validation_results['nested_cv']['mean_score']
                        nested_std = rf_model.validation_results['nested_cv']['std_score']
                        print(f"   üéØ Valida√ß√£o Aninhada: {nested_score:.4f} ¬± {nested_std:.4f}")
                    
                    # Features selecionadas
                    if 'rfe' in rf_model.feature_analysis_results:
                        optimal_features = rf_model.feature_analysis_results['rfe']['optimal_features']
                        total_features = len(rf_model.feature_analysis_results['rfe']['feature_ranking'])
                        print(f"   üß¨ Features Otimizadas: {optimal_features}/{total_features}")
                    
                    # Estabilidade
                    if 'stability' in rf_model.validation_results:
                        stability_cv = rf_model.validation_results['stability']['score_stability']['coefficient_variation']
                        stability_level = "Alta" if stability_cv < 0.05 else "M√©dia" if stability_cv < 0.10 else "Baixa"
                        print(f"   üìä Estabilidade do Modelo: {stability_level} (CV: {stability_cv:.4f})")
                    
                    # Multicolinearidade
                    if 'multicollinearity' in rf_model.feature_analysis_results:
                        high_corr = len(rf_model.feature_analysis_results['multicollinearity'].get('high_correlation_pairs', []))
                        print(f"   üîó Pares Correlacionados: {high_corr}")
                    
                    # Intera√ß√µes
                    if 'interactions' in rf_model.feature_analysis_results:
                        interactions = len(rf_model.feature_analysis_results['interactions']['pairwise_interactions'])
                        if interactions > 0:
                            best_improvement = rf_model.feature_analysis_results['interactions']['pairwise_interactions'][0]['improvement']
                            print(f"   ‚ö° Melhor Intera√ß√£o: {best_improvement:+.4f} melhoria")
                    
                    # Relat√≥rios
                    if rf_model.advanced_reports:
                        print(f"   üìã Relat√≥rios Avan√ßados Gerados:")
                        if 'validation' in rf_model.advanced_reports:
                            print(f"      ‚Ä¢ Valida√ß√£o Robusta")
                        if 'features' in rf_model.advanced_reports:
                            print(f"      ‚Ä¢ An√°lise de Features")
            else:
                print(f"‚ùå Erro na execu√ß√£o do Random Forest")
                
        except ImportError as e:
            print(f"‚ö†Ô∏è Random Forest n√£o dispon√≠vel: {e}")
        except Exception as e:
            print(f"‚ùå Erro no Random Forest: {e}")
            import traceback
            traceback.print_exc()
        
        # Compara√ß√£o de modelos (se m√∫ltiplos foram treinados)
        if len(trained_models) > 1:
            print(f"\nüìä COMPARA√á√ÉO DE MODELOS:")
            print(f"{'='*70}")
            print(f"{'Modelo':<20}{'Accuracy':<12}{'Precision':<12}{'Recall':<12}{'F1-Score':<12}{'ROC-AUC':<12}")
            print(f"{'='*70}")
            
            for model_name, model in trained_models.items():
                name_display = model_name.replace('_', ' ').title()
                if hasattr(model, 'metrics'):
                    acc = model.metrics.get('accuracy', 0)
                    prec = model.metrics.get('precision', 0)
                    rec = model.metrics.get('recall', 0)
                    f1 = model.metrics.get('f1', 0)
                    auc = model.metrics.get('roc_auc', 0)
                elif hasattr(model, 'evaluation_results'):
                    metrics = model.evaluation_results
                    acc = metrics.get('accuracy', 0)
                    prec = metrics.get('precision', 0)
                    rec = metrics.get('recall', 0)
                    f1 = metrics.get('f1', 0)
                    auc = metrics.get('roc_auc', 0)
                else:
                    acc = prec = rec = f1 = auc = 0
                    
                print(f"{name_display:<20}{acc:<12.4f}{prec:<12.4f}{rec:<12.4f}{f1:<12.4f}{auc:<12.4f}")
        
        # ‚ú® SE√á√ÉO ESPECIAL PARA AN√ÅLISES AVAN√áADAS ‚ú®
        if advanced_analysis and not fast_mode and 'random_forest' in trained_models:
            print(f"\nüî¨ RESUMO DAS AN√ÅLISES AVAN√áADAS:")
            print(f"{'='*70}")
            
            rf_model = trained_models['random_forest']
            
            # Mostrar benef√≠cios das an√°lises
            print(f"üéØ BENEF√çCIOS OBTIDOS:")
            
            # Valida√ß√£o robusta
            if 'nested_cv' in rf_model.validation_results:
                nested_score = rf_model.validation_results['nested_cv']['mean_score']
                basic_score = rf_model.metrics.get('roc_auc', 0)
                reliability = "Alta" if abs(nested_score - basic_score) < 0.02 else "M√©dia"
                print(f"   ‚úÖ Confiabilidade da Valida√ß√£o: {reliability}")
                print(f"      Score Aninhado: {nested_score:.4f}")
                print(f"      Score B√°sico: {basic_score:.4f}")
            
            # Otimiza√ß√£o de features
            if 'rfe' in rf_model.feature_analysis_results:
                original_features = len(rf_model.feature_analysis_results['rfe']['feature_ranking'])
                optimal_features = rf_model.feature_analysis_results['rfe']['optimal_features']
                reduction = (1 - optimal_features/original_features) * 100
                print(f"   ‚úÖ Redu√ß√£o de Features: {reduction:.1f}%")
                print(f"      Original: {original_features} ‚Üí Otimizado: {optimal_features}")
            
            # Estabilidade
            if 'stability' in rf_model.validation_results:
                stability = rf_model.validation_results['stability']['score_stability']
                cv = stability['coefficient_variation']
                stability_grade = "A" if cv < 0.05 else "B" if cv < 0.10 else "C"
                print(f"   ‚úÖ Nota de Estabilidade: {stability_grade}")
                print(f"      Coeficiente de Varia√ß√£o: {cv:.4f}")
            
            # Insights de features
            if 'feature_stability' in rf_model.feature_analysis_results:
                stable_features = len(rf_model.feature_analysis_results['feature_stability']['top_stable_features'])
                unstable_features = len(rf_model.feature_analysis_results['feature_stability']['unstable_features'])
                print(f"   ‚úÖ Features Est√°veis: {stable_features}")
                print(f"   ‚ö†Ô∏è  Features Inst√°veis: {unstable_features}")
            
            print(f"\nüìã RECURSOS ADICIONAIS DISPON√çVEIS:")
            print(f"   ÔøΩ Dashboard Interativo (requer: pip install dash plotly)")
            print(f"   üìà An√°lise SHAP (requer: pip install shap)")
            print(f"   üìë Relat√≥rios Detalhados em: {RESULTS_DIR}")
        
        print(f"\nÔøΩüíæ Modelos salvos em: {MODELS_DIR}")
        print(f"üìä Resultados salvos em: {RESULTS_DIR}")
        
        if fast_mode:
            print(f"‚ö° Modo r√°pido: algumas an√°lises avan√ßadas foram puladas")
        elif not advanced_analysis:
            print(f"üìù Modo b√°sico: an√°lises avan√ßadas n√£o executadas")
        
        # Retornar o melhor modelo
        best_model = None
        best_score = 0
        
        for model_name, model in trained_models.items():
            if hasattr(model, 'metrics') and 'roc_auc' in model.metrics:
                score = model.metrics['roc_auc']
            elif hasattr(model, 'evaluation_results') and 'roc_auc' in model.evaluation_results:
                score = model.evaluation_results['roc_auc']
            else:
                score = 0
            
            if score > best_score:
                best_score = score
                best_model = model
        
        return best_model or trained_models.get('logistic_regression') or trained_models.get('random_forest')
            
    except Exception as e:
        print(f"‚ùå Erro no treinamento dos modelos: {e}")
        import traceback
        traceback.print_exc()
        return None
        raise


def print_pipeline_summary(X_train, X_test, y_train, y_test, lr_model, execution_time):
    """Imprime resumo final do pipeline"""
    print("\n" + "üéØ" + "="*68 + "üéØ")
    print("    PIPELINE EXECUTADO COM SUCESSO!")
    print("üéØ" + "="*68 + "üéØ")
    
    print(f"\nüìä RESUMO DOS DADOS:")
    print(f"   ‚Ä¢ Conjunto de treino: {X_train.shape[0]:,} amostras")
    print(f"   ‚Ä¢ Conjunto de teste: {X_test.shape[0]:,} amostras")  
    print(f"   ‚Ä¢ Total de features: {X_train.shape[1]:,}")
    print(f"   ‚Ä¢ Taxa de readmiss√£o (treino): {y_train.mean():.1%}")
    print(f"   ‚Ä¢ Taxa de readmiss√£o (teste): {y_test.mean():.1%}")
    
    print(f"\nü§ñ MODELOS TREINADOS:")
    if lr_model:
        print(f"   ‚úÖ Regress√£o Log√≠stica")
        if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
            metrics = lr_model.evaluation_results
            print(f"      ‚îî‚îÄ Accuracy: {metrics.get('accuracy', 0):.1%}")
            print(f"      ‚îî‚îÄ F1-Score: {metrics.get('f1', 0):.1%}")
            print(f"      ‚îî‚îÄ ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
    else:
        print(f"   ‚ùå Nenhum modelo treinado com sucesso")
    
    print(f"\nüìÅ ARQUIVOS GERADOS:")
    print(f"   ‚Ä¢ Dados limpos: {os.path.basename(CLEAN_DATA_FILE)}")
    print(f"   ‚Ä¢ Dados processados: {os.path.basename(PROCESSED_DATA_FILE)}")
    print(f"   ‚Ä¢ Conjuntos de treino/teste: data/X_train.csv, X_test.csv, y_train.csv, y_test.csv")
    print(f"   ‚Ä¢ Modelos treinados: models/")
    print(f"   ‚Ä¢ Relat√≥rios e gr√°ficos: results/")
    
    print(f"\n‚è±Ô∏è TEMPO DE EXECU√á√ÉO: {execution_time:.1f} segundos")


def handle_pipeline_error(error, stage=""):
    """Trata erros do pipeline de forma padronizada"""
    print(f"\n‚ùå ERRO NO PIPELINE{' - ' + stage if stage else ''}")
    print(f"   Tipo: {type(error).__name__}")
    print(f"   Mensagem: {str(error)}")
    print(f"\nüìã Detalhes t√©cnicos:")
    traceback.print_exc()
    
    print(f"\nüí° Sugest√µes para resolu√ß√£o:")
    print(f"   ‚Ä¢ Verifique se os arquivos de dados est√£o presentes")
    print(f"   ‚Ä¢ Confirme se todas as depend√™ncias est√£o instaladas")
    print(f"   ‚Ä¢ Execute: python scripts/validate_setup.py")
    print(f"   ‚Ä¢ Consulte os logs de erro para mais detalhes")


def main(fast_mode=False):
    """Fun√ß√£o principal que executa todo o pipeline de forma robusta"""
    # Inicializar timing
    start_time = time.time()
    
    # Imprimir cabe√ßalho
    print_pipeline_header()
    
    if fast_mode:
        print("‚ö° MODO R√ÅPIDO ATIVADO - Sem otimiza√ß√£o de hiperpar√¢metros")
        print("=" * 70)
    
    # Vari√°veis para tracking de resultados
    X_train = X_test = y_train = y_test = lr_model = None
    
    try:
        # Verificar e criar diret√≥rios necess√°rios
        ensure_directories()
        
        # Etapa 1: An√°lise Explorat√≥ria
        df_analyzed = run_exploratory_analysis()
        
        # Etapa 2: Limpeza dos Dados
        df_clean = run_data_cleaning()
        
        # Etapa 3: Engenharia de Features
        X_train, X_test, y_train, y_test = run_feature_engineering()
        
        # Etapa 4: Modelos de Machine Learning
        lr_model = run_machine_learning_models(fast_mode=fast_mode)
        
        # Calcular tempo de execu√ß√£o
        execution_time = time.time() - start_time
        
        # Imprimir resumo final
        print_pipeline_summary(X_train, X_test, y_train, y_test, lr_model, execution_time)
        
        # Retornar resultados principais
        return {
            'X_train': X_train,
            'X_test': X_test, 
            'y_train': y_train,
            'y_test': y_test,
            'model': lr_model,
            'execution_time': execution_time,
            'fast_mode': fast_mode
        }
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è Pipeline interrompido pelo usu√°rio")
        print(f"   Tempo decorrido: {time.time() - start_time:.1f} segundos")
        return None
        
    except FileNotFoundError as e:
        handle_pipeline_error(e, "Arquivo n√£o encontrado")
        print(f"\nüí° Verifique se o arquivo de dados existe em: {RAW_DATA_FILE}")
        return None
        
    except ImportError as e:
        handle_pipeline_error(e, "Depend√™ncia n√£o encontrada")
        print(f"\nüí° Execute: pip install -r requirements.txt")
        return None
        
    except Exception as e:
        handle_pipeline_error(e, "Erro geral")
        return None


def quick_demo():
    """Execu√ß√£o r√°pida para demonstra√ß√£o (apenas modelo, sem an√°lise explorat√≥ria completa)"""
    print("üöÄ DEMONSTRA√á√ÉO R√ÅPIDA - APENAS MODELAGEM")
    print("="*50)
    
    try:
        lr_model = LogisticRegressionModel()
        success = lr_model.run_complete_pipeline(tune_hyperparams=False, optimize_threshold=True)
        
        if success:
            print("‚úÖ Demonstra√ß√£o conclu√≠da com sucesso!")
            if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
                metrics = lr_model.evaluation_results
                print(f"üìà M√©tricas principais:")
                print(f"   ‚Ä¢ Accuracy: {metrics.get('accuracy', 0):.1%}")
                print(f"   ‚Ä¢ F1-Score: {metrics.get('f1', 0):.1%}")
                print(f"   ‚Ä¢ ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
        else:
            print("‚ùå Erro na demonstra√ß√£o")
            
    except Exception as e:
        print(f"‚ùå Erro: {e}")


if __name__ == "__main__":
    # Verificar argumentos da linha de comando
    if len(sys.argv) > 1:
        if sys.argv[1] == '--demo':
            quick_demo()
        elif sys.argv[1] == '--fast':
            result = main(fast_mode=True)
        else:
            print("Uso: python main_pipeline.py [--demo|--fast]")
            print("  --demo: Apenas demonstra√ß√£o do modelo")
            print("  --fast: Pipeline completo sem otimiza√ß√£o de hiperpar√¢metros") 
            sys.exit(1)
    else:
        result = main(fast_mode=False)
    
    # Exit code baseado no sucesso
    if 'result' in locals() and result is None:
        sys.exit(1)
    else:
        sys.exit(0)
