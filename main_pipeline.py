"""
Script principal para execu√ß√£o do pipeline completo de an√°lise de readmiss√£o hospitalar diab√©tica

Este script executa todas as etapas do projeto:
1. An√°lise explorat√≥ria dos dados
2. Limpeza e pr√©-processamento dos dados  
3. Engenharia de features e prepara√ß√£o para modelagem
4. Treinamento e avalia√ß√£o do modelo de Regress√£o Log√≠stica
5. Gera√ß√£o de relat√≥rios e visualiza√ß√µes

Uso:
    python main_pipeline.py                # Pipeline completo
    python main_pipeline.py --demo        # Demonstra√ß√£o r√°pida (apenas modelagem)
    python main_pipeline.py --fast        # Pipeline completo sem otimiza√ß√£o de hiperpar√¢metros

Autor: Projeto BCC325 - Intelig√™ncia Artificial UFOP
Data: 2025
"""

import os
import sys
import time
import traceback
from datetime import datetime

# Adicionar diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importa√ß√µes dos m√≥dulos do projeto
from src.exploratory_analysis import ExploratoryDataAnalysis
from src.data_cleaning import DataCleaner
from src.feature_engineering import FeatureEngineer
from src.logistic_regression_model import LogisticRegressionModel
from src.config import (
    RAW_DATA_FILE, CLEAN_DATA_FILE, PROCESSED_DATA_FILE,
    MODELS_DIR, RESULTS_DIR, DATA_DIR
)


def ensure_directories():
    """Garante que todos os diret√≥rios necess√°rios existam"""
    directories = [DATA_DIR, RESULTS_DIR, MODELS_DIR]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"‚úì Diret√≥rio verificado: {directory}")


def print_pipeline_header():
    """Imprime cabe√ßalho do pipeline"""
    print("üè•" + "="*70 + "üè•")
    print("    PIPELINE COMPLETO DE AN√ÅLISE DE READMISS√ÉO HOSPITALAR DIAB√âTICA")
    print("    Projeto: BCC325 - Intelig√™ncia Artificial - UFOP")
    print("    Dataset: UCI Diabetes 130-US hospitals (1999-2008)")
    print("    Objetivo: Predizer readmiss√£o em < 30 dias")
    print("üè•" + "="*70 + "üè•")


def print_stage_header(stage_num, stage_name, description=""):
    """Imprime cabe√ßalho padronizado para cada etapa"""
    print(f"\n{'='*20} ETAPA {stage_num}: {stage_name.upper()} {'='*20}")
    if description:
        print(f"Objetivo: {description}")
    print("=" * (42 + len(stage_name)))


def run_exploratory_analysis():
    """Executa an√°lise explorat√≥ria dos dados"""
    print_stage_header(1, "An√°lise Explorat√≥ria", 
                      "Compreens√£o inicial dos dados, identifica√ß√£o de padr√µes e problemas")
    
    try:
        eda = ExploratoryDataAnalysis(RAW_DATA_FILE)
        df_analyzed = eda.run_complete_analysis()
        
        print(f"‚úÖ An√°lise explorat√≥ria conclu√≠da!")
        print(f"   üìä Dataset: {df_analyzed.shape[0]:,} registros, {df_analyzed.shape[1]} colunas")
        print(f"   üìÅ Relat√≥rios gerados em: {RESULTS_DIR}")
        
        return df_analyzed
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise explorat√≥ria: {e}")
        raise


def run_data_cleaning():
    """Executa limpeza e pr√©-processamento dos dados"""
    print_stage_header(2, "Limpeza dos Dados", 
                      "Tratamento de dados faltantes, remo√ß√£o de inconsist√™ncias")
    
    try:
        cleaner = DataCleaner(RAW_DATA_FILE)
        df_clean = cleaner.clean_data(CLEAN_DATA_FILE)
        
        # Mostrar resumo da limpeza
        cleaner.get_cleaning_summary()
        
        # Obter estat√≠sticas diretamente dos dados
        original_records = cleaner.cleaning_stats.get('original_records', 'N/A')
        final_records = len(df_clean) if df_clean is not None else 0
        removed_records = (original_records - final_records) if isinstance(original_records, int) else 'N/A'
        
        print(f"‚úÖ Limpeza dos dados conclu√≠da!")
        print(f"   üìä Registros originais: {original_records:,}" if isinstance(original_records, int) else f"   üìä Registros originais: {original_records}")
        print(f"   üìä Registros finais: {final_records:,}")
        print(f"   üóëÔ∏è Registros removidos: {removed_records:,}" if isinstance(removed_records, int) else f"   üóëÔ∏è Registros removidos: {removed_records}")
        print(f"   üíæ Dados limpos salvos em: {CLEAN_DATA_FILE}")
        
        return df_clean
        
    except Exception as e:
        print(f"‚ùå Erro na limpeza dos dados: {e}")
        raise


def run_feature_engineering():
    """Executa engenharia de features e prepara√ß√£o para modelagem"""
    print_stage_header(3, "Engenharia de Features", 
                      "Transforma√ß√£o e prepara√ß√£o final dos dados para modelagem")
    
    try:
        engineer = FeatureEngineer(CLEAN_DATA_FILE)
        
        # Processar features e obter conjuntos de treino/teste
        X_train, X_test, y_train, y_test = engineer.process_features(PROCESSED_DATA_FILE)
        
        # Salvar datasets processados
        engineer.save_processed_datasets()
        
        # Obter relat√≥rio de processamento
        report = engineer.get_processing_report()
        
        print(f"‚úÖ Engenharia de features conclu√≠da!")
        print(f"   üéØ Conjunto de treino: {X_train.shape[0]:,} amostras, {X_train.shape[1]} features")
        print(f"   üéØ Conjunto de teste: {X_test.shape[0]:,} amostras, {X_test.shape[1]} features")
        print(f"   üìä Taxa de readmiss√£o (treino): {y_train.mean():.1%}")
        print(f"   üìä Taxa de readmiss√£o (teste): {y_test.mean():.1%}")
        print(f"   üíæ Datasets salvos em: {DATA_DIR}")
        
        return X_train, X_test, y_train, y_test
        
    except Exception as e:
        print(f"‚ùå Erro na engenharia de features: {e}")
        raise


def run_machine_learning_models(fast_mode=False):
    """Executa treinamento e avalia√ß√£o do modelo de Regress√£o Log√≠stica"""
    print_stage_header(4, "Modelagem de Machine Learning", 
                      "Treinamento e avalia√ß√£o do modelo de Regress√£o Log√≠stica")
    
    try:
        # Inicializar modelo de Regress√£o Log√≠stica
        print("ü§ñ Inicializando Regress√£o Log√≠stica...")
        lr_model = LogisticRegressionModel()
        
        # Executar pipeline completo do modelo (com ou sem otimiza√ß√£o)
        success = lr_model.run_complete_pipeline(
            tune_hyperparams=not fast_mode,    # Otimizar hiperpar√¢metros apenas se n√£o estiver em modo r√°pido
            optimize_threshold=True            # Sempre otimizar limiar de decis√£o
        )
        
        if success:
            print(f"‚úÖ Regress√£o Log√≠stica executada com sucesso!")
            
            # Mostrar m√©tricas principais
            if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
                metrics = lr_model.evaluation_results
                print(f"   üìà Accuracy: {metrics.get('accuracy', 0):.1%}")
                print(f"   üìà Precision: {metrics.get('precision', 0):.1%}")
                print(f"   üìà Recall: {metrics.get('recall', 0):.1%}")
                print(f"   üìà F1-Score: {metrics.get('f1', 0):.1%}")
                print(f"   üìà ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
                
            print(f"   üíæ Modelo salvo em: {MODELS_DIR}")
            print(f"   üìä Resultados salvos em: {RESULTS_DIR}")
            
            if fast_mode:
                print(f"   ‚ö° Modo r√°pido: hiperpar√¢metros padr√£o utilizados")
            
            return lr_model
        else:
            print(f"‚ùå Erro na execu√ß√£o da Regress√£o Log√≠stica")
            return None
            
    except Exception as e:
        print(f"‚ùå Erro no treinamento do modelo: {e}")
        raise


def print_pipeline_summary(X_train, X_test, y_train, y_test, lr_model, execution_time):
    """Imprime resumo final do pipeline"""
    print("\n" + "üéØ" + "="*68 + "üéØ")
    print("    PIPELINE EXECUTADO COM SUCESSO!")
    print("üéØ" + "="*68 + "üéØ")
    
    print(f"\nüìä RESUMO DOS DADOS:")
    print(f"   ‚Ä¢ Conjunto de treino: {X_train.shape[0]:,} amostras")
    print(f"   ‚Ä¢ Conjunto de teste: {X_test.shape[0]:,} amostras")  
    print(f"   ‚Ä¢ Total de features: {X_train.shape[1]:,}")
    print(f"   ‚Ä¢ Taxa de readmiss√£o (treino): {y_train.mean():.1%}")
    print(f"   ‚Ä¢ Taxa de readmiss√£o (teste): {y_test.mean():.1%}")
    
    print(f"\nü§ñ MODELOS TREINADOS:")
    if lr_model:
        print(f"   ‚úÖ Regress√£o Log√≠stica")
        if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
            metrics = lr_model.evaluation_results
            print(f"      ‚îî‚îÄ Accuracy: {metrics.get('accuracy', 0):.1%}")
            print(f"      ‚îî‚îÄ F1-Score: {metrics.get('f1', 0):.1%}")
            print(f"      ‚îî‚îÄ ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
    else:
        print(f"   ‚ùå Nenhum modelo treinado com sucesso")
    
    print(f"\nüìÅ ARQUIVOS GERADOS:")
    print(f"   ‚Ä¢ Dados limpos: {os.path.basename(CLEAN_DATA_FILE)}")
    print(f"   ‚Ä¢ Dados processados: {os.path.basename(PROCESSED_DATA_FILE)}")
    print(f"   ‚Ä¢ Conjuntos de treino/teste: data/X_train.csv, X_test.csv, y_train.csv, y_test.csv")
    print(f"   ‚Ä¢ Modelos treinados: models/")
    print(f"   ‚Ä¢ Relat√≥rios e gr√°ficos: results/")
    
    print(f"\n‚è±Ô∏è TEMPO DE EXECU√á√ÉO: {execution_time:.1f} segundos")
    
    print(f"\nüî¨ INTERPRETA√á√ÉO CL√çNICA:")
    print(f"   ‚Ä¢ O modelo pode auxiliar na identifica√ß√£o de pacientes com maior risco")
    print(f"   ‚Ä¢ √ötil para otimiza√ß√£o de recursos hospitalares e cuidados preventivos")
    print(f"   ‚Ä¢ Recomenda-se valida√ß√£o adicional com dados mais recentes")
    
    print(f"\nüöÄ PR√ìXIMOS PASSOS SUGERIDOS:")
    print(f"   ‚Ä¢ Implementar Random Forest e XGBoost para compara√ß√£o")
    print(f"   ‚Ä¢ Valida√ß√£o cruzada mais robusta")
    print(f"   ‚Ä¢ An√°lise de feature importance mais detalhada")
    print(f"   ‚Ä¢ Implementa√ß√£o em ambiente de produ√ß√£o")


def handle_pipeline_error(error, stage=""):
    """Trata erros do pipeline de forma padronizada"""
    print(f"\n‚ùå ERRO NO PIPELINE{' - ' + stage if stage else ''}")
    print(f"   Tipo: {type(error).__name__}")
    print(f"   Mensagem: {str(error)}")
    print(f"\nüìã Detalhes t√©cnicos:")
    traceback.print_exc()
    
    print(f"\nüí° Sugest√µes para resolu√ß√£o:")
    print(f"   ‚Ä¢ Verifique se os arquivos de dados est√£o presentes")
    print(f"   ‚Ä¢ Confirme se todas as depend√™ncias est√£o instaladas")
    print(f"   ‚Ä¢ Execute: python scripts/validate_setup.py")
    print(f"   ‚Ä¢ Consulte os logs de erro para mais detalhes")


def main(fast_mode=False):
    """Fun√ß√£o principal que executa todo o pipeline de forma robusta"""
    # Inicializar timing
    start_time = time.time()
    
    # Imprimir cabe√ßalho
    print_pipeline_header()
    
    if fast_mode:
        print("‚ö° MODO R√ÅPIDO ATIVADO - Sem otimiza√ß√£o de hiperpar√¢metros")
        print("=" * 70)
    
    # Vari√°veis para tracking de resultados
    X_train = X_test = y_train = y_test = lr_model = None
    
    try:
        # Verificar e criar diret√≥rios necess√°rios
        ensure_directories()
        
        # Etapa 1: An√°lise Explorat√≥ria
        df_analyzed = run_exploratory_analysis()
        
        # Etapa 2: Limpeza dos Dados
        df_clean = run_data_cleaning()
        
        # Etapa 3: Engenharia de Features
        X_train, X_test, y_train, y_test = run_feature_engineering()
        
        # Etapa 4: Modelos de Machine Learning
        lr_model = run_machine_learning_models(fast_mode=fast_mode)
        
        # Calcular tempo de execu√ß√£o
        execution_time = time.time() - start_time
        
        # Imprimir resumo final
        print_pipeline_summary(X_train, X_test, y_train, y_test, lr_model, execution_time)
        
        # Retornar resultados principais
        return {
            'X_train': X_train,
            'X_test': X_test, 
            'y_train': y_train,
            'y_test': y_test,
            'model': lr_model,
            'execution_time': execution_time,
            'fast_mode': fast_mode
        }
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è Pipeline interrompido pelo usu√°rio")
        print(f"   Tempo decorrido: {time.time() - start_time:.1f} segundos")
        return None
        
    except FileNotFoundError as e:
        handle_pipeline_error(e, "Arquivo n√£o encontrado")
        print(f"\nüí° Verifique se o arquivo de dados existe em: {RAW_DATA_FILE}")
        return None
        
    except ImportError as e:
        handle_pipeline_error(e, "Depend√™ncia n√£o encontrada")
        print(f"\nüí° Execute: pip install -r requirements.txt")
        return None
        
    except Exception as e:
        handle_pipeline_error(e, "Erro geral")
        return None


def quick_demo():
    """Execu√ß√£o r√°pida para demonstra√ß√£o (apenas modelo, sem an√°lise explorat√≥ria completa)"""
    print("üöÄ DEMONSTRA√á√ÉO R√ÅPIDA - APENAS MODELAGEM")
    print("="*50)
    
    try:
        lr_model = LogisticRegressionModel()
        success = lr_model.run_complete_pipeline(tune_hyperparams=False, optimize_threshold=True)
        
        if success:
            print("‚úÖ Demonstra√ß√£o conclu√≠da com sucesso!")
            if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
                metrics = lr_model.evaluation_results
                print(f"üìà M√©tricas principais:")
                print(f"   ‚Ä¢ Accuracy: {metrics.get('accuracy', 0):.1%}")
                print(f"   ‚Ä¢ F1-Score: {metrics.get('f1', 0):.1%}")
                print(f"   ‚Ä¢ ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
        else:
            print("‚ùå Erro na demonstra√ß√£o")
            
    except Exception as e:
        print(f"‚ùå Erro: {e}")


if __name__ == "__main__":
    # Verificar argumentos da linha de comando
    if len(sys.argv) > 1:
        if sys.argv[1] == '--demo':
            quick_demo()
        elif sys.argv[1] == '--fast':
            result = main(fast_mode=True)
        else:
            print("Uso: python main_pipeline.py [--demo|--fast]")
            print("  --demo: Apenas demonstra√ß√£o do modelo")
            print("  --fast: Pipeline completo sem otimiza√ß√£o de hiperpar√¢metros") 
            sys.exit(1)
    else:
        result = main(fast_mode=False)
    
    # Exit code baseado no sucesso
    if 'result' in locals() and result is None:
        sys.exit(1)
    else:
        sys.exit(0)
