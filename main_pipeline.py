"""
Pipeline Principal de An√°lise de Readmiss√£o Hospitalar Diab√©tica

Este script orquestra a execu√ß√£o completa do pipeline de Machine Learning, incluindo:
1. An√°lise Explorat√≥ria de Dados (EDA) - Compreens√£o inicial dos padr√µes
2. Limpeza e Pr√©-processamento - Tratamento de dados faltantes e inconsist√™ncias  
3. Engenharia de Features - Transforma√ß√£o e prepara√ß√£o para modelagem
4. Treinamento de Modelos ML - Regress√£o Log√≠stica e Random Forest
5. Avalia√ß√£o e Valida√ß√£o - M√©tricas de performance e visualiza√ß√µes
6. Gera√ß√£o de Relat√≥rios - Documenta√ß√£o completa dos resultados

Modos de Execu√ß√£o:
    python main_pipeline.py                # Pipeline completo com otimiza√ß√µes
    python main_pipeline.py --demo        # Demonstra√ß√£o r√°pida (apenas modelagem)
    python main_pipeline.py --fast        # Pipeline completo sem otimiza√ß√£o de hiperpar√¢metros

Autor: Thalles Felipe Rodrigues de Almeida Santos
Projeto: Predi√ß√£o de Readmiss√£o Hospitalar em Pacientes com Diabetes Usando Aprendizado de M√°quina
Institui√ß√£o: Universidade Federal de Ouro Preto (UFOP)
Disciplina: Intelig√™ncia Artificial
Professor: Jadson Castro Gertrudes
Data: Agosto 2025

"""

import os
import sys
import time
import traceback
from datetime import datetime

# Adicionar diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importa√ß√µes dos m√≥dulos do projeto
from src.exploratory_analysis import ExploratoryDataAnalysis
from src.data_cleaning import DataCleaner
from src.feature_engineering import FeatureEngineer
from src.logistic_regression_model import LogisticRegressionModel
from src.config import (
    RAW_DATA_FILE, CLEAN_DATA_FILE, PROCESSED_DATA_FILE,
    MODELS_DIR, RESULTS_DIR, DATA_DIR
)


def ensure_directories():
    """Garante que todos os diret√≥rios necess√°rios existam"""
    directories = [DATA_DIR, RESULTS_DIR, MODELS_DIR]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"‚úì Diret√≥rio verificado: {directory}")


def print_pipeline_header():
    """Imprime cabe√ßalho do pipeline"""
    print("üè•" + "="*70 + "üè•")
    print("    PIPELINE COMPLETO DE AN√ÅLISE DE READMISS√ÉO HOSPITALAR DIAB√âTICA")
    print("    Projeto: Predi√ß√£o de Readmiss√£o Hospitalar em Pacientes com Diabetes Usando Aprendizado de M√°quina")
    print("    Dataset: UCI Diabetes 130-US hospitals (1999-2008)")
    print("    Objetivo: Predizer readmiss√£o em < 30 dias")
    print("üè•" + "="*70 + "üè•")


def print_stage_header(stage_num, stage_name, description=""):
    """Imprime cabe√ßalho padronizado para cada etapa"""
    print(f"\n{'='*20} ETAPA {stage_num}: {stage_name.upper()} {'='*20}")
    if description:
        print(f"Objetivo: {description}")
    print("=" * (42 + len(stage_name)))


def run_exploratory_analysis():
    """Executa an√°lise explorat√≥ria dos dados"""
    print_stage_header(1, "An√°lise Explorat√≥ria", 
                      "Compreens√£o inicial dos dados, identifica√ß√£o de padr√µes e problemas")
    
    try:
        eda = ExploratoryDataAnalysis(RAW_DATA_FILE)
        df_analyzed = eda.run_complete_analysis()
        
        print(f"‚úÖ An√°lise explorat√≥ria conclu√≠da!")
        print(f"   üìä Dataset: {df_analyzed.shape[0]:,} registros, {df_analyzed.shape[1]} colunas")
        print(f"   üìÅ Relat√≥rios gerados em: {RESULTS_DIR}")
        
        return df_analyzed
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise explorat√≥ria: {e}")
        raise


def run_data_cleaning():
    """Executa limpeza e pr√©-processamento dos dados"""
    print_stage_header(2, "Limpeza dos Dados", 
                      "Tratamento de dados faltantes, remo√ß√£o de inconsist√™ncias")
    
    try:
        cleaner = DataCleaner(RAW_DATA_FILE)
        df_clean = cleaner.clean_data(CLEAN_DATA_FILE)
        
        # Mostrar resumo da limpeza
        cleaner.get_cleaning_summary()
        
        # Obter estat√≠sticas diretamente dos dados
        original_records = cleaner.cleaning_stats.get('original_records', 'N/A')
        final_records = len(df_clean) if df_clean is not None else 0
        removed_records = (original_records - final_records) if isinstance(original_records, int) else 'N/A'
        
        print(f"‚úÖ Limpeza dos dados conclu√≠da!")
        print(f"   üìä Registros originais: {original_records:,}" if isinstance(original_records, int) else f"   üìä Registros originais: {original_records}")
        print(f"   üìä Registros finais: {final_records:,}")
        print(f"   üóëÔ∏è Registros removidos: {removed_records:,}" if isinstance(removed_records, int) else f"   üóëÔ∏è Registros removidos: {removed_records}")
        print(f"   üíæ Dados limpos salvos em: {CLEAN_DATA_FILE}")
        
        return df_clean
        
    except Exception as e:
        print(f"‚ùå Erro na limpeza dos dados: {e}")
        raise


def run_feature_engineering():
    """Executa engenharia de features e prepara√ß√£o para modelagem"""
    print_stage_header(3, "Engenharia de Features", 
                      "Transforma√ß√£o e prepara√ß√£o final dos dados para modelagem")
    
    try:
        engineer = FeatureEngineer(CLEAN_DATA_FILE)
        
        # Processar features e obter conjuntos de treino/teste
        X_train, X_test, y_train, y_test = engineer.process_features(PROCESSED_DATA_FILE)
        
        # Salvar datasets processados
        engineer.save_processed_datasets()
        
        # Obter relat√≥rio de processamento
        report = engineer.get_processing_report()
        
        print(f"‚úÖ Engenharia de features conclu√≠da!")
        print(f"   üéØ Conjunto de treino: {X_train.shape[0]:,} amostras, {X_train.shape[1]} features")
        print(f"   üéØ Conjunto de teste: {X_test.shape[0]:,} amostras, {X_test.shape[1]} features")
        print(f"   üìä Taxa de readmiss√£o (treino): {y_train.mean():.1%}")
        print(f"   üìä Taxa de readmiss√£o (teste): {y_test.mean():.1%}")
        print(f"   üíæ Datasets salvos em: {DATA_DIR}")
        
        return X_train, X_test, y_train, y_test
        
    except Exception as e:
        print(f"‚ùå Erro na engenharia de features: {e}")
        raise


def run_machine_learning_models(fast_mode=False):
    """Executa treinamento e avalia√ß√£o de modelos de Machine Learning"""
    print_stage_header(4, "Modelagem de Machine Learning", 
                      "Treinamento e avalia√ß√£o de m√∫ltiplos modelos preditivos")
    
    trained_models = {}
    
    try:
        # 1. Regress√£o Log√≠stica
        print("ü§ñ Inicializando Regress√£o Log√≠stica...")
        lr_model = LogisticRegressionModel()
        
        # Executar pipeline completo do modelo (com ou sem otimiza√ß√£o)
        lr_success = lr_model.run_complete_pipeline(
            tune_hyperparams=not fast_mode,    # Otimizar hiperpar√¢metros apenas se n√£o estiver em modo r√°pido
            optimize_threshold=True            # Sempre otimizar limiar de decis√£o
        )
        
        if lr_success:
            trained_models['logistic_regression'] = lr_model
            print(f"‚úÖ Regress√£o Log√≠stica executada com sucesso!")
            
            # Mostrar m√©tricas principais
            if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
                metrics = lr_model.evaluation_results
                print(f"   üìà Accuracy: {metrics.get('accuracy', 0):.1%}")
                print(f"   üìà Precision: {metrics.get('precision', 0):.1%}")
                print(f"   üìà Recall: {metrics.get('recall', 0):.1%}")
                print(f"   üìà F1-Score: {metrics.get('f1', 0):.1%}")
                print(f"   üìà ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
            
        else:
            print(f"‚ùå Erro na execu√ß√£o da Regress√£o Log√≠stica")
        
        # 2. Random Forest
        print("\nüå≤ Inicializando Random Forest...")
        
        try:
            from src.random_forest_model import RandomForestModel
            
            rf_model = RandomForestModel()
            
            if fast_mode:
                print("‚ö° Modo r√°pido: configura√ß√µes otimizadas sem busca")
                # Configurar para demo r√°pida
                rf_model.model_config.update({
                    'n_estimators': 200,
                    'max_depth': 12,
                    'min_samples_split': 8,
                    'min_samples_leaf': 3
                })
                rf_success = rf_model.run_complete_pipeline(
                    tune_hyperparams=False,
                    optimize_threshold=True,
                    cv_folds=3
                )
            else:
                rf_success = rf_model.run_complete_pipeline(
                    tune_hyperparams=True,
                    method='random_search',
                    optimize_threshold=True
                )
            
            if rf_success:
                trained_models['random_forest'] = rf_model
                print(f"‚úÖ Random Forest executado com sucesso!")
                print(f"   üìà Accuracy: {rf_model.metrics['accuracy']:.1%}")
                print(f"   üìà Precision: {rf_model.metrics['precision']:.1%}")
                print(f"   üìà Recall: {rf_model.metrics['recall']:.1%}")
                print(f"   üìà F1-Score: {rf_model.metrics['f1']:.1%}")
                print(f"   üìà ROC-AUC: {rf_model.metrics['roc_auc']:.3f}")
                if rf_model.oob_score:
                    print(f"   üìà OOB Score: {rf_model.oob_score:.3f}")
            else:
                print(f"‚ùå Erro na execu√ß√£o do Random Forest")
                
        except ImportError as e:
            print(f"‚ö†Ô∏è Random Forest n√£o dispon√≠vel: {e}")
        except Exception as e:
            print(f"‚ùå Erro no Random Forest: {e}")
            import traceback
            traceback.print_exc()
        
        # Compara√ß√£o de modelos (se m√∫ltiplos foram treinados)
        if len(trained_models) > 1:
            print(f"\nüìä COMPARA√á√ÉO DE MODELOS:")
            print(f"{'='*70}")
            print(f"{'Modelo':<20}{'Accuracy':<12}{'Precision':<12}{'Recall':<12}{'F1-Score':<12}{'ROC-AUC':<12}")
            print(f"{'='*70}")
            
            for model_name, model in trained_models.items():
                name_display = model_name.replace('_', ' ').title()
                if hasattr(model, 'metrics'):
                    acc = model.metrics.get('accuracy', 0)
                    prec = model.metrics.get('precision', 0)
                    rec = model.metrics.get('recall', 0)
                    f1 = model.metrics.get('f1', 0)
                    auc = model.metrics.get('roc_auc', 0)
                elif hasattr(model, 'evaluation_results'):
                    metrics = model.evaluation_results
                    acc = metrics.get('accuracy', 0)
                    prec = metrics.get('precision', 0)
                    rec = metrics.get('recall', 0)
                    f1 = metrics.get('f1', 0)
                    auc = metrics.get('roc_auc', 0)
                else:
                    acc = prec = rec = f1 = auc = 0
                    
                print(f"{name_display:<20}{acc:<12.4f}{prec:<12.4f}{rec:<12.4f}{f1:<12.4f}{auc:<12.4f}")
        
        print(f"\nüíæ Modelos salvos em: {MODELS_DIR}")
        print(f"üìä Resultados salvos em: {RESULTS_DIR}")
        
        if fast_mode:
            print(f"‚ö° Modo r√°pido: hiperpar√¢metros padr√£o utilizados")
        
        # Retornar o primeiro modelo para compatibilidade
        return trained_models.get('logistic_regression') or trained_models.get('random_forest')
            
    except Exception as e:
        print(f"‚ùå Erro no treinamento dos modelos: {e}")
        import traceback
        traceback.print_exc()
        return None
        raise


def print_pipeline_summary(X_train, X_test, y_train, y_test, lr_model, execution_time):
    """Imprime resumo final do pipeline"""
    print("\n" + "üéØ" + "="*68 + "üéØ")
    print("    PIPELINE EXECUTADO COM SUCESSO!")
    print("üéØ" + "="*68 + "üéØ")
    
    print(f"\nüìä RESUMO DOS DADOS:")
    print(f"   ‚Ä¢ Conjunto de treino: {X_train.shape[0]:,} amostras")
    print(f"   ‚Ä¢ Conjunto de teste: {X_test.shape[0]:,} amostras")  
    print(f"   ‚Ä¢ Total de features: {X_train.shape[1]:,}")
    print(f"   ‚Ä¢ Taxa de readmiss√£o (treino): {y_train.mean():.1%}")
    print(f"   ‚Ä¢ Taxa de readmiss√£o (teste): {y_test.mean():.1%}")
    
    print(f"\nü§ñ MODELOS TREINADOS:")
    if lr_model:
        print(f"   ‚úÖ Regress√£o Log√≠stica")
        if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
            metrics = lr_model.evaluation_results
            print(f"      ‚îî‚îÄ Accuracy: {metrics.get('accuracy', 0):.1%}")
            print(f"      ‚îî‚îÄ F1-Score: {metrics.get('f1', 0):.1%}")
            print(f"      ‚îî‚îÄ ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
    else:
        print(f"   ‚ùå Nenhum modelo treinado com sucesso")
    
    print(f"\nüìÅ ARQUIVOS GERADOS:")
    print(f"   ‚Ä¢ Dados limpos: {os.path.basename(CLEAN_DATA_FILE)}")
    print(f"   ‚Ä¢ Dados processados: {os.path.basename(PROCESSED_DATA_FILE)}")
    print(f"   ‚Ä¢ Conjuntos de treino/teste: data/X_train.csv, X_test.csv, y_train.csv, y_test.csv")
    print(f"   ‚Ä¢ Modelos treinados: models/")
    print(f"   ‚Ä¢ Relat√≥rios e gr√°ficos: results/")
    
    print(f"\n‚è±Ô∏è TEMPO DE EXECU√á√ÉO: {execution_time:.1f} segundos")
    
    print(f"\nüöÄ PR√ìXIMOS PASSOS SUGERIDOS:")
    print(f"   ‚Ä¢ Implementar Random Forest e XGBoost para compara√ß√£o")
    print(f"   ‚Ä¢ Valida√ß√£o cruzada mais robusta")
    print(f"   ‚Ä¢ An√°lise de feature importance mais detalhada")
    print(f"   ‚Ä¢ Implementa√ß√£o em ambiente de produ√ß√£o")


def handle_pipeline_error(error, stage=""):
    """Trata erros do pipeline de forma padronizada"""
    print(f"\n‚ùå ERRO NO PIPELINE{' - ' + stage if stage else ''}")
    print(f"   Tipo: {type(error).__name__}")
    print(f"   Mensagem: {str(error)}")
    print(f"\nüìã Detalhes t√©cnicos:")
    traceback.print_exc()
    
    print(f"\nüí° Sugest√µes para resolu√ß√£o:")
    print(f"   ‚Ä¢ Verifique se os arquivos de dados est√£o presentes")
    print(f"   ‚Ä¢ Confirme se todas as depend√™ncias est√£o instaladas")
    print(f"   ‚Ä¢ Execute: python scripts/validate_setup.py")
    print(f"   ‚Ä¢ Consulte os logs de erro para mais detalhes")


def main(fast_mode=False):
    """Fun√ß√£o principal que executa todo o pipeline de forma robusta"""
    # Inicializar timing
    start_time = time.time()
    
    # Imprimir cabe√ßalho
    print_pipeline_header()
    
    if fast_mode:
        print("‚ö° MODO R√ÅPIDO ATIVADO - Sem otimiza√ß√£o de hiperpar√¢metros")
        print("=" * 70)
    
    # Vari√°veis para tracking de resultados
    X_train = X_test = y_train = y_test = lr_model = None
    
    try:
        # Verificar e criar diret√≥rios necess√°rios
        ensure_directories()
        
        # Etapa 1: An√°lise Explorat√≥ria
        df_analyzed = run_exploratory_analysis()
        
        # Etapa 2: Limpeza dos Dados
        df_clean = run_data_cleaning()
        
        # Etapa 3: Engenharia de Features
        X_train, X_test, y_train, y_test = run_feature_engineering()
        
        # Etapa 4: Modelos de Machine Learning
        lr_model = run_machine_learning_models(fast_mode=fast_mode)
        
        # Calcular tempo de execu√ß√£o
        execution_time = time.time() - start_time
        
        # Imprimir resumo final
        print_pipeline_summary(X_train, X_test, y_train, y_test, lr_model, execution_time)
        
        # Retornar resultados principais
        return {
            'X_train': X_train,
            'X_test': X_test, 
            'y_train': y_train,
            'y_test': y_test,
            'model': lr_model,
            'execution_time': execution_time,
            'fast_mode': fast_mode
        }
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è Pipeline interrompido pelo usu√°rio")
        print(f"   Tempo decorrido: {time.time() - start_time:.1f} segundos")
        return None
        
    except FileNotFoundError as e:
        handle_pipeline_error(e, "Arquivo n√£o encontrado")
        print(f"\nüí° Verifique se o arquivo de dados existe em: {RAW_DATA_FILE}")
        return None
        
    except ImportError as e:
        handle_pipeline_error(e, "Depend√™ncia n√£o encontrada")
        print(f"\nüí° Execute: pip install -r requirements.txt")
        return None
        
    except Exception as e:
        handle_pipeline_error(e, "Erro geral")
        return None


def quick_demo():
    """Execu√ß√£o r√°pida para demonstra√ß√£o (apenas modelo, sem an√°lise explorat√≥ria completa)"""
    print("üöÄ DEMONSTRA√á√ÉO R√ÅPIDA - APENAS MODELAGEM")
    print("="*50)
    
    try:
        lr_model = LogisticRegressionModel()
        success = lr_model.run_complete_pipeline(tune_hyperparams=False, optimize_threshold=True)
        
        if success:
            print("‚úÖ Demonstra√ß√£o conclu√≠da com sucesso!")
            if hasattr(lr_model, 'evaluation_results') and lr_model.evaluation_results:
                metrics = lr_model.evaluation_results
                print(f"üìà M√©tricas principais:")
                print(f"   ‚Ä¢ Accuracy: {metrics.get('accuracy', 0):.1%}")
                print(f"   ‚Ä¢ F1-Score: {metrics.get('f1', 0):.1%}")
                print(f"   ‚Ä¢ ROC-AUC: {metrics.get('roc_auc', 0):.3f}")
        else:
            print("‚ùå Erro na demonstra√ß√£o")
            
    except Exception as e:
        print(f"‚ùå Erro: {e}")


if __name__ == "__main__":
    # Verificar argumentos da linha de comando
    if len(sys.argv) > 1:
        if sys.argv[1] == '--demo':
            quick_demo()
        elif sys.argv[1] == '--fast':
            result = main(fast_mode=True)
        else:
            print("Uso: python main_pipeline.py [--demo|--fast]")
            print("  --demo: Apenas demonstra√ß√£o do modelo")
            print("  --fast: Pipeline completo sem otimiza√ß√£o de hiperpar√¢metros") 
            sys.exit(1)
    else:
        result = main(fast_mode=False)
    
    # Exit code baseado no sucesso
    if 'result' in locals() and result is None:
        sys.exit(1)
    else:
        sys.exit(0)
