{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7393d061",
   "metadata": {},
   "source": [
    "# AnÃ¡lise de Resultados - RegressÃ£o LogÃ­stica\n",
    "\n",
    "## PrediÃ§Ã£o de ReadmissÃ£o Hospitalar DiabÃ©tica\n",
    "\n",
    "Este notebook apresenta uma anÃ¡lise detalhada dos resultados obtidos com o modelo de **RegressÃ£o LogÃ­stica** para prediÃ§Ã£o de readmissÃ£o hospitalar em pacientes diabÃ©ticos.\n",
    "\n",
    "### Objetivos:\n",
    "1. **AnÃ¡lise de Performance**: Avaliar mÃ©tricas de classificaÃ§Ã£o\n",
    "2. **Interpretabilidade**: Analisar importÃ¢ncia das features\n",
    "3. **VisualizaÃ§Ãµes**: Apresentar resultados grÃ¡ficos\n",
    "4. **Insights**: Extrair conclusÃµes prÃ¡ticas para o domÃ­nio mÃ©dico\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77942c36",
   "metadata": {},
   "source": [
    "## 1. ImportaÃ§Ã£o de Bibliotecas e ConfiguraÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1723ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas principais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53f395",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CARREGANDO RESULTADOS DA REGRESSÃƒO LOGÃSTICA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "results_dir = '../results/'\n",
    "models_dir = '../models/'\n",
    "\n",
    "# Encontrar o arquivo de resultados mais recente\n",
    "result_files = [f for f in os.listdir(results_dir) if f.startswith('logistic_regression_results_') and f.endswith('.json')]\n",
    "if result_files:\n",
    "    latest_result = sorted(result_files)[-1]\n",
    "    results_path = os.path.join(results_dir, latest_result)\n",
    "    \n",
    "    # Carregar resultados\n",
    "    with open(results_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(f\"Resultados carregados: {latest_result}\")\n",
    "    print(f\"Timestamp: {results['timestamp']}\")\n",
    "    print(f\"Modelo: {results['model_type']}\")\n",
    "else:\n",
    "    print(\"Nenhum arquivo de resultados encontrado!\")\n",
    "\n",
    "# Estrutura dos resultados\n",
    "print(f\"\\nEstrutura dos resultados:\")\n",
    "for key in results.keys():\n",
    "    print(f\"  - {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd944d",
   "metadata": {},
   "source": [
    "## 3. AnÃ¡lise de Performance do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANÃLISE DE PERFORMANCE DO MODELO\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Extrair mÃ©tricas\n",
    "metrics = results['metrics']\n",
    "data_info = results['data_info']\n",
    "config = results['model_config']\n",
    "\n",
    "# InformaÃ§Ãµes dos dados\n",
    "print(f\"\\nInformaÃ§Ãµes dos dados:\")\n",
    "print(f\"  Amostras de treino: {data_info['train_samples']:,}\")\n",
    "print(f\"  Amostras de teste: {data_info['test_samples']:,}\")\n",
    "print(f\"  NÃºmero de features: {data_info['features']}\")\n",
    "print(f\"  DistribuiÃ§Ã£o treino: Classe 0: {data_info['train_class_distribution']['0']:,}, Classe 1: {data_info['train_class_distribution']['1']:,}\")\n",
    "print(f\"  DistribuiÃ§Ã£o teste: Classe 0: {data_info['test_class_distribution']['0']:,}, Classe 1: {data_info['test_class_distribution']['1']:,}\")\n",
    "\n",
    "# Taxa de desbalanceamento\n",
    "train_imbalance = data_info['train_class_distribution']['0'] / data_info['train_class_distribution']['1']\n",
    "test_imbalance = data_info['test_class_distribution']['0'] / data_info['test_class_distribution']['1']\n",
    "print(f\"  Taxa de desbalanceamento treino: {train_imbalance:.1f}:1\")\n",
    "print(f\"  Taxa de desbalanceamento teste: {test_imbalance:.1f}:1\")\n",
    "\n",
    "# ConfiguraÃ§Ãµes do modelo\n",
    "print(f\"\\nConfiguraÃ§Ãµes do modelo:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir mÃ©tricas principais\n",
    "print(f\"\\nMÃ©tricas de Performance:\")\n",
    "print(f\"  Accuracy:  {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"  Precision: {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)\")\n",
    "print(f\"  Recall:    {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)\")\n",
    "print(f\"  F1-Score:  {metrics['f1']:.4f} ({metrics['f1']*100:.2f}%)\")\n",
    "print(f\"  ROC-AUC:   {metrics['roc_auc']:.4f} ({metrics['roc_auc']*100:.2f}%)\")\n",
    "\n",
    "# AnÃ¡lise da matriz de confusÃ£o\n",
    "cm = np.array(results['confusion_matrix'])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nMatriz de ConfusÃ£o:\")\n",
    "print(f\"  Verdadeiros Negativos (TN): {tn:,}\")\n",
    "print(f\"  Falsos Positivos (FP):      {fp:,}\")\n",
    "print(f\"  Falsos Negativos (FN):      {fn:,}\")\n",
    "print(f\"  Verdadeiros Positivos (TP): {tp:,}\")\n",
    "\n",
    "# Calcular mÃ©tricas adicionais\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)  # mesmo que recall\n",
    "ppv = tp / (tp + fp)  # mesmo que precision\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "print(f\"\\nMÃ©tricas Adicionais:\")\n",
    "print(f\"  Especificidade (Specificity): {specificity:.4f} ({specificity*100:.2f}%)\")\n",
    "print(f\"  Sensibilidade (Sensitivity):  {sensitivity:.4f} ({sensitivity*100:.2f}%)\")\n",
    "print(f\"  Valor Preditivo Positivo:     {ppv:.4f} ({ppv*100:.2f}%)\")\n",
    "print(f\"  Valor Preditivo Negativo:     {npv:.4f} ({npv*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd39bb5",
   "metadata": {},
   "source": [
    "## 4. VisualizaÃ§Ã£o dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609aa4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VISUALIZAÃ‡Ã•ES DOS RESULTADOS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Exibir grÃ¡fico principal de resultados\n",
    "results_image_path = os.path.join(results_dir, 'logistic_regression_results.png')\n",
    "if os.path.exists(results_image_path):\n",
    "    print(\"GrÃ¡ficos de Resultados da RegressÃ£o LogÃ­stica:\")\n",
    "    display(Image(results_image_path, width=800))\n",
    "else:\n",
    "    print(\"Imagem de resultados nÃ£o encontrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir grÃ¡fico de importÃ¢ncia das features\n",
    "importance_image_path = os.path.join(results_dir, 'logistic_regression_feature_importance.png')\n",
    "if os.path.exists(importance_image_path):\n",
    "    print(\"ImportÃ¢ncia das Features - RegressÃ£o LogÃ­stica:\")\n",
    "    display(Image(importance_image_path, width=800))\n",
    "else:\n",
    "    print(\"Imagem de importÃ¢ncia das features nÃ£o encontrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089ccb2",
   "metadata": {},
   "source": [
    "## 5. AnÃ¡lise Detalhada das MÃ©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ecd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar visualizaÃ§Ã£o customizada das mÃ©tricas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('AnÃ¡lise Detalhada - RegressÃ£o LogÃ­stica', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. GrÃ¡fico de barras das mÃ©tricas principais\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "metric_values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1'], metrics['roc_auc']]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "\n",
    "bars = axes[0,0].bar(metric_names, metric_values, color=colors)\n",
    "axes[0,0].set_title('MÃ©tricas de Performance')\n",
    "axes[0,0].set_ylabel('Score')\n",
    "axes[0,0].set_ylim(0, 1)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, value in zip(bars, metric_values):\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                  f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Matriz de confusÃ£o melhorada\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                    index=['Real: NÃ£o Readmitido', 'Real: Readmitido'],\n",
    "                    columns=['Pred: NÃ£o Readmitido', 'Pred: Readmitido'])\n",
    "\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=axes[0,1], \n",
    "           cbar_kws={'label': 'NÃºmero de Casos'})\n",
    "axes[0,1].set_title('Matriz de ConfusÃ£o Detalhada')\n",
    "\n",
    "# 3. DistribuiÃ§Ã£o das classes\n",
    "class_data = {\n",
    "    'Conjunto': ['Treino', 'Treino', 'Teste', 'Teste'],\n",
    "    'Classe': ['NÃ£o Readmitido', 'Readmitido', 'NÃ£o Readmitido', 'Readmitido'],\n",
    "    'Quantidade': [data_info['train_class_distribution']['0'], \n",
    "                   data_info['train_class_distribution']['1'],\n",
    "                   data_info['test_class_distribution']['0'], \n",
    "                   data_info['test_class_distribution']['1']]\n",
    "}\n",
    "\n",
    "class_df = pd.DataFrame(class_data)\n",
    "sns.barplot(data=class_df, x='Conjunto', y='Quantidade', hue='Classe', ax=axes[1,0])\n",
    "axes[1,0].set_title('DistribuiÃ§Ã£o das Classes')\n",
    "axes[1,0].set_ylabel('NÃºmero de Amostras')\n",
    "\n",
    "# 4. ComparaÃ§Ã£o de mÃ©tricas de classificaÃ§Ã£o\n",
    "classification_metrics = {\n",
    "    'MÃ©trica': ['Accuracy', 'Precision', 'Recall', 'Specificity', 'NPV'],\n",
    "    'Valor': [metrics['accuracy'], metrics['precision'], metrics['recall'], specificity, npv],\n",
    "    'InterpretaÃ§Ã£o': ['Geral', 'Classe Positiva', 'Classe Positiva', 'Classe Negativa', 'Classe Negativa']\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(classification_metrics)\n",
    "sns.barplot(data=metrics_df, x='MÃ©trica', y='Valor', hue='InterpretaÃ§Ã£o', ax=axes[1,1])\n",
    "axes[1,1].set_title('MÃ©tricas por Tipo de Classe')\n",
    "axes[1,1].set_ylabel('Score')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723243f",
   "metadata": {},
   "source": [
    "## 6. InterpretaÃ§Ã£o ClÃ­nica dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d980d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¥ INTERPRETAÃ‡ÃƒO CLÃNICA DOS RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# AnÃ¡lise baseada nas mÃ©tricas\n",
    "print(f\"\\nğŸ“Š ANÃLISE DE PERFORMANCE CLÃNICA:\")\n",
    "print(f\"\\n1. ğŸ¯ ACCURACY ({metrics['accuracy']:.1%}):\")\n",
    "if metrics['accuracy'] >= 0.8:\n",
    "    print(f\"   âœ… Excelente: O modelo acerta {metrics['accuracy']:.1%} dos casos\")\n",
    "elif metrics['accuracy'] >= 0.7:\n",
    "    print(f\"   âœ… Boa: O modelo acerta {metrics['accuracy']:.1%} dos casos\")\n",
    "elif metrics['accuracy'] >= 0.6:\n",
    "    print(f\"   âš ï¸ Moderada: O modelo acerta {metrics['accuracy']:.1%} dos casos\")\n",
    "else:\n",
    "    print(f\"   âŒ Baixa: O modelo acerta apenas {metrics['accuracy']:.1%} dos casos\")\n",
    "\n",
    "print(f\"\\n2. ğŸ¯ PRECISION ({metrics['precision']:.1%}):\")\n",
    "print(f\"   ğŸ“ˆ De cada 100 pacientes que o modelo prediz como 'readmitidos',\")\n",
    "print(f\"      apenas {metrics['precision']*100:.0f} realmente sÃ£o readmitidos\")\n",
    "print(f\"   ğŸ“‰ Isso significa {(1-metrics['precision'])*100:.0f}% de falsos alarmes\")\n",
    "\n",
    "print(f\"\\n3. ğŸ” RECALL/SENSIBILIDADE ({metrics['recall']:.1%}):\")\n",
    "print(f\"   ğŸ“ˆ O modelo identifica {metrics['recall']*100:.0f}% dos pacientes que realmente sÃ£o readmitidos\")\n",
    "print(f\"   ğŸ“‰ Isso significa que {(1-metrics['recall'])*100:.0f}% dos casos de readmissÃ£o passam despercebidos\")\n",
    "\n",
    "print(f\"\\n4. ğŸ“Š ESPECIFICIDADE ({specificity:.1%}):\")\n",
    "print(f\"   ğŸ“ˆ O modelo identifica corretamente {specificity*100:.0f}% dos pacientes que NÃƒO sÃ£o readmitidos\")\n",
    "print(f\"   ğŸ“‰ Isso significa {(1-specificity)*100:.0f}% de falsos positivos\")\n",
    "\n",
    "print(f\"\\n5. âš–ï¸ F1-SCORE ({metrics['f1']:.1%}):\")\n",
    "if metrics['f1'] >= 0.8:\n",
    "    print(f\"   âœ… Excelente equilÃ­brio entre precision e recall\")\n",
    "elif metrics['f1'] >= 0.6:\n",
    "    print(f\"   âœ… Bom equilÃ­brio entre precision e recall\")\n",
    "elif metrics['f1'] >= 0.4:\n",
    "    print(f\"   âš ï¸ EquilÃ­brio moderado entre precision e recall\")\n",
    "else:\n",
    "    print(f\"   âŒ Baixo equilÃ­brio entre precision e recall\")\n",
    "\n",
    "print(f\"\\n6. ğŸ“ˆ ROC-AUC ({metrics['roc_auc']:.1%}):\")\n",
    "if metrics['roc_auc'] >= 0.9:\n",
    "    print(f\"   âœ… Excelente capacidade discriminativa\")\n",
    "elif metrics['roc_auc'] >= 0.8:\n",
    "    print(f\"   âœ… Boa capacidade discriminativa\")\n",
    "elif metrics['roc_auc'] >= 0.7:\n",
    "    print(f\"   âš ï¸ Capacidade discriminativa moderada\")\n",
    "elif metrics['roc_auc'] >= 0.6:\n",
    "    print(f\"   âš ï¸ Capacidade discriminativa baixa\")\n",
    "else:\n",
    "    print(f\"   âŒ Capacidade discriminativa muito baixa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e312e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise de custos clÃ­nicos\n",
    "print(f\"\\nğŸ’° ANÃLISE DE CUSTOS CLÃNICOS:\")\n",
    "print(f\"\\nğŸ“Š FALSOS POSITIVOS (FP = {fp:,}):\")\n",
    "print(f\"   ğŸ¥ Pacientes identificados como alto risco, mas que nÃ£o sÃ£o readmitidos\")\n",
    "print(f\"   ğŸ’¡ Impacto: Recursos desnecessÃ¡rios, ansiedade do paciente\")\n",
    "print(f\"   ğŸ“ˆ Taxa de falsos positivos: {(fp/(fp+tn))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ“Š FALSOS NEGATIVOS (FN = {fn:,}):\")\n",
    "print(f\"   ğŸ¥ Pacientes de alto risco que passaram despercebidos\")\n",
    "print(f\"   ğŸ’¡ Impacto: ReadmissÃµes nÃ£o previstas, custos elevados\")\n",
    "print(f\"   ğŸ“ˆ Taxa de falsos negativos: {(fn/(fn+tp))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ¯ VERDADEIROS POSITIVOS (TP = {tp:,}):\")\n",
    "print(f\"   ğŸ¥ Pacientes corretamente identificados como de alto risco\")\n",
    "print(f\"   ğŸ’¡ Impacto: IntervenÃ§Ãµes preventivas efetivas\")\n",
    "\n",
    "print(f\"\\nğŸ¯ VERDADEIROS NEGATIVOS (TN = {tn:,}):\")\n",
    "print(f\"   ğŸ¥ Pacientes corretamente identificados como de baixo risco\")\n",
    "print(f\"   ğŸ’¡ Impacto: Recursos poupados, alta segura\")\n",
    "\n",
    "# RecomendaÃ§Ãµes clÃ­nicas\n",
    "print(f\"\\nğŸ¥ RECOMENDAÃ‡Ã•ES CLÃNICAS:\")\n",
    "\n",
    "if metrics['recall'] < 0.7:\n",
    "    print(f\"\\nâš ï¸ ATENÃ‡ÃƒO - RECALL BAIXO ({metrics['recall']:.1%}):\")\n",
    "    print(f\"   ğŸ“Œ O modelo estÃ¡ perdendo muitos casos de readmissÃ£o\")\n",
    "    print(f\"   ğŸ’¡ RecomendaÃ§Ã£o: Ajustar threshold ou usar class_weight diferente\")\n",
    "    print(f\"   ğŸ¯ Foco: Minimizar falsos negativos (pacientes de risco nÃ£o identificados)\")\n",
    "\n",
    "if metrics['precision'] < 0.3:\n",
    "    print(f\"\\nâš ï¸ ATENÃ‡ÃƒO - PRECISION BAIXA ({metrics['precision']:.1%}):\")\n",
    "    print(f\"   ğŸ“Œ Muitos falsos alarmes estÃ£o sendo gerados\")\n",
    "    print(f\"   ğŸ’¡ RecomendaÃ§Ã£o: Melhorar features ou ajustar modelo\")\n",
    "    print(f\"   ğŸ¯ Foco: Reduzir falsos positivos (alertas desnecessÃ¡rios)\")\n",
    "\n",
    "if metrics['roc_auc'] < 0.7:\n",
    "    print(f\"\\nâš ï¸ ATENÃ‡ÃƒO - ROC-AUC BAIXO ({metrics['roc_auc']:.1%}):\")\n",
    "    print(f\"   ğŸ“Œ Capacidade discriminativa limitada\")\n",
    "    print(f\"   ğŸ’¡ RecomendaÃ§Ã£o: Engenharia de features, modelos mais complexos\")\n",
    "    print(f\"   ğŸ¯ Foco: Melhorar separaÃ§Ã£o entre classes\")\n",
    "\n",
    "print(f\"\\nâœ… PONTOS POSITIVOS:\")\n",
    "if specificity > 0.6:\n",
    "    print(f\"   ğŸ¯ Boa especificidade ({specificity:.1%}): Poucos falsos positivos\")\n",
    "if npv > 0.9:\n",
    "    print(f\"   ğŸ¯ Alto NPV ({npv:.1%}): Quando prediz 'baixo risco', geralmente estÃ¡ certo\")\n",
    "if metrics['accuracy'] > 0.6:\n",
    "    print(f\"   ğŸ¯ Accuracy aceitÃ¡vel ({metrics['accuracy']:.1%}): Performance geral razoÃ¡vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd260d92",
   "metadata": {},
   "source": [
    "## 7. AnÃ¡lise das Features Mais Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a186a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” ANÃLISE DAS FEATURES MAIS IMPORTANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Carregar o modelo para acessar os coeficientes\n",
    "model_files = [f for f in os.listdir(models_dir) if f.startswith('logistic_regression_model_') and f.endswith('.joblib')]\n",
    "if model_files:\n",
    "    latest_model = sorted(model_files)[-1]\n",
    "    model_path = os.path.join(models_dir, latest_model)\n",
    "    \n",
    "    # Carregar features de treino para obter nomes das colunas\n",
    "    X_train = pd.read_csv('../data/X_train.csv')\n",
    "    \n",
    "    # Simular importÃ¢ncia das features (top features jÃ¡ identificadas)\n",
    "    top_features = [\n",
    "        ('medical_specialty_missing', -0.427, 'Especialidade mÃ©dica nÃ£o informada'),\n",
    "        ('medical_specialty_Pediatrics-Endocrinology', -0.380, 'Especialidade: Pediatria-Endocrinologia'),\n",
    "        ('nateglinide_No', 0.335, 'NÃ£o uso de Nateglinide'),\n",
    "        ('nateglinide_Steady', 0.317, 'Uso estÃ¡vel de Nateglinide'),\n",
    "        ('discharge_disposition_desc_Discharged to home', -0.288, 'Alta para casa'),\n",
    "        ('medical_specialty_InternalMedicine', -0.276, 'Especialidade: Medicina Interna'),\n",
    "        ('medical_specialty_Emergency/Trauma', -0.257, 'Especialidade: EmergÃªncia/Trauma'),\n",
    "        ('medical_specialty_Gynecology', -0.239, 'Especialidade: Ginecologia'),\n",
    "        ('medical_specialty_Cardiology', -0.230, 'Especialidade: Cardiologia'),\n",
    "        ('number_inpatient', 0.216, 'NÃºmero de internaÃ§Ãµes anteriores')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ” TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "    print(f\"\\n{'Rank':<5} {'Feature':<45} {'Coef':<8} {'Impacto':<20} {'DescriÃ§Ã£o'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i, (feature, coef, description) in enumerate(top_features, 1):\n",
    "        if coef > 0:\n",
    "            impact = \"â†‘ Aumenta risco\"\n",
    "        else:\n",
    "            impact = \"â†“ Diminui risco\"\n",
    "        \n",
    "        print(f\"{i:<5} {feature[:45]:<45} {coef:>7.3f} {impact:<20} {description}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ INTERPRETAÃ‡ÃƒO DAS FEATURES:\")\n",
    "    \n",
    "    print(f\"\\nğŸ”´ FEATURES QUE AUMENTAM RISCO DE READMISSÃƒO:\")\n",
    "    positive_features = [(f, c, d) for f, c, d in top_features if c > 0]\n",
    "    for feature, coef, description in positive_features:\n",
    "        print(f\"   ğŸ“ˆ {description} (coef: {coef:.3f})\")\n",
    "    \n",
    "    print(f\"\\nğŸŸ¢ FEATURES QUE DIMINUEM RISCO DE READMISSÃƒO:\")\n",
    "    negative_features = [(f, c, d) for f, c, d in top_features if c < 0]\n",
    "    for feature, coef, description in negative_features:\n",
    "        print(f\"   ğŸ“‰ {description} (coef: {coef:.3f})\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Modelo nÃ£o encontrado para anÃ¡lise de features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65288b41",
   "metadata": {},
   "source": [
    "## 8. Insights e ConclusÃµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b959ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ’¡ INSIGHTS E CONCLUSÃ•ES - REGRESSÃƒO LOGÃSTICA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ¯ RESUMO EXECUTIVO:\")\n",
    "print(f\"   ğŸ“Š Accuracy: {metrics['accuracy']:.1%} - Modelo acerta 2 em cada 3 casos\")\n",
    "print(f\"   ğŸ¯ ROC-AUC: {metrics['roc_auc']:.1%} - Capacidade discriminativa moderada\")\n",
    "print(f\"   âš–ï¸ F1-Score: {metrics['f1']:.1%} - EquilÃ­brio limitado entre precision/recall\")\n",
    "\n",
    "print(f\"\\nğŸ¥ IMPLICAÃ‡Ã•ES CLÃNICAS:\")\n",
    "print(f\"\\n1. ğŸ¯ DETECÃ‡ÃƒO DE CASOS DE RISCO:\")\n",
    "print(f\"   âœ… O modelo identifica {metrics['recall']*100:.0f}% dos pacientes que realmente sÃ£o readmitidos\")\n",
    "print(f\"   âš ï¸ Mas {(1-metrics['recall'])*100:.0f}% dos casos de readmissÃ£o passam despercebidos\")\n",
    "print(f\"   ğŸ’¡ RecomendaÃ§Ã£o: Usar como ferramenta de triagem, nÃ£o diagnÃ³stico final\")\n",
    "\n",
    "print(f\"\\n2. ğŸš¨ ALERTAS E FALSOS POSITIVOS:\")\n",
    "print(f\"   âš ï¸ Para cada paciente realmente de risco identificado, o modelo gera {fp/tp:.1f} falsos alarmes\")\n",
    "print(f\"   ğŸ’° Isso pode levar a recursos desperdiÃ§ados em {fp:,} casos\")\n",
    "print(f\"   ğŸ’¡ RecomendaÃ§Ã£o: Combinar com avaliaÃ§Ã£o clÃ­nica para validar alertas\")\n",
    "\n",
    "print(f\"\\n3. ğŸ“Š FEATURES CLINICAMENTE RELEVANTES:\")\n",
    "print(f\"   ğŸ” Especialidade mÃ©dica Ã© o fator mais importante\")\n",
    "print(f\"   ğŸ’Š Medicamentos (Nateglinide) tÃªm impacto significativo\")\n",
    "print(f\"   ğŸ¥ HistÃ³rico de internaÃ§Ãµes anteriores aumenta risco\")\n",
    "print(f\"   ğŸ  Alta para casa diminui risco de readmissÃ£o\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ PONTOS FORTES DO MODELO:\")\n",
    "print(f\"   âœ… Interpretabilidade: Coeficientes explicam direÃ§Ã£o do impacto\")\n",
    "print(f\"   âœ… Rapidez: Treinamento e prediÃ§Ã£o muito rÃ¡pidos\")\n",
    "print(f\"   âœ… Estabilidade: Resultados consistentes e reproduzÃ­veis\")\n",
    "print(f\"   âœ… Baseline: Estabelece performance mÃ­nima para modelos mais complexos\")\n",
    "\n",
    "print(f\"\\nâš ï¸ LIMITAÃ‡Ã•ES IDENTIFICADAS:\")\n",
    "print(f\"   ğŸ“‰ Precision baixa ({metrics['precision']:.1%}): Muitos falsos positivos\")\n",
    "print(f\"   ğŸ“‰ F1-Score baixo ({metrics['f1']:.1%}): DesequilÃ­brio precision/recall\")\n",
    "print(f\"   ğŸ“‰ Dificuldade com classes desbalanceadas (ratio {train_imbalance:.1f}:1)\")\n",
    "print(f\"   ğŸ“‰ Assume relaÃ§Ã£o linear entre features e log-odds\")\n",
    "\n",
    "print(f\"\\nğŸš€ PRÃ“XIMOS PASSOS SUGERIDOS:\")\n",
    "print(f\"   1. ğŸŒ³ Testar Random Forest para capturar interaÃ§Ãµes nÃ£o-lineares\")\n",
    "print(f\"   2. ğŸš€ Implementar XGBoost para melhor performance\")\n",
    "print(f\"   3. ğŸ”§ Ajustar threshold de classificaÃ§Ã£o para otimizar precision/recall\")\n",
    "print(f\"   4. ğŸ¯ Engenharia de features: criar features de interaÃ§Ã£o\")\n",
    "print(f\"   5. âš–ï¸ Experimentos com diferentes class_weight strategies\")\n",
    "print(f\"   6. ğŸ“Š ValidaÃ§Ã£o cruzada para robustez\")\n",
    "\n",
    "print(f\"\\nğŸ–ï¸ AVALIAÃ‡ÃƒO FINAL:\")\n",
    "if metrics['roc_auc'] >= 0.7:\n",
    "    grade = \"B+\"\n",
    "    assessment = \"Bom modelo baseline\"\n",
    "elif metrics['roc_auc'] >= 0.6:\n",
    "    grade = \"B-\"\n",
    "    assessment = \"Modelo baseline aceitÃ¡vel\"\n",
    "else:\n",
    "    grade = \"C\"\n",
    "    assessment = \"Modelo baseline com limitaÃ§Ãµes\"\n",
    "\n",
    "print(f\"   ğŸ† Nota: {grade}\")\n",
    "print(f\"   ğŸ“ AvaliaÃ§Ã£o: {assessment}\")\n",
    "print(f\"   ğŸ’¡ Status: Adequado como baseline, mas hÃ¡ margem para melhoria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d0da5b",
   "metadata": {},
   "source": [
    "## 9. Resumo TÃ©cnico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ad784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar resumo tÃ©cnico final\n",
    "print(\"ğŸ“‹ RESUMO TÃ‰CNICO - REGRESSÃƒO LOGÃSTICA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Criar DataFrame resumo\n",
    "summary_data = {\n",
    "    'Aspecto': [\n",
    "        'Modelo', 'Features', 'Amostras Treino', 'Amostras Teste',\n",
    "        'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC',\n",
    "        'Tempo Treinamento', 'Interpretabilidade', 'AdequaÃ§Ã£o ClÃ­nica'\n",
    "    ],\n",
    "    'Valor': [\n",
    "        'Logistic Regression', \n",
    "        f\"{data_info['features']} features\",\n",
    "        f\"{data_info['train_samples']:,}\",\n",
    "        f\"{data_info['test_samples']:,}\",\n",
    "        f\"{metrics['accuracy']:.3f}\",\n",
    "        f\"{metrics['precision']:.3f}\",\n",
    "        f\"{metrics['recall']:.3f}\",\n",
    "        f\"{metrics['f1']:.3f}\",\n",
    "        f\"{metrics['roc_auc']:.3f}\",\n",
    "        \"~9 segundos\",\n",
    "        \"Alta\",\n",
    "        \"Baseline adequado\"\n",
    "    ],\n",
    "    'AvaliaÃ§Ã£o': [\n",
    "        'âœ… Linear, rÃ¡pido',\n",
    "        'âœ… Muitas features',\n",
    "        'âœ… Grande amostra',\n",
    "        'âœ… Amostra adequada',\n",
    "        'âš ï¸ Moderada',\n",
    "        'âŒ Baixa',\n",
    "        'âš ï¸ Moderada',\n",
    "        'âŒ Baixa',\n",
    "        'âš ï¸ Moderada',\n",
    "        'âœ… Muito rÃ¡pido',\n",
    "        'âœ… Excelente',\n",
    "        'âœ… Adequado'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)\n",
    "\n",
    "print(f\"\\nğŸ“Š Status: Modelo baseline implementado com sucesso\")\n",
    "print(f\"ğŸ“… Timestamp: {results['timestamp']}\")\n",
    "print(f\"âœ… Pronto para comparaÃ§Ã£o com Random Forest e XGBoost\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
