"""
M√≥dulo para an√°lise explorat√≥ria dos dados de readmiss√£o hospitalar diab√©tica

Este m√≥dulo implementa uma an√°lise explorat√≥ria completa com visualiza√ß√µes gr√°ficas,
estat√≠sticas descritivas detalhadas e an√°lises de rela√ß√µes entre vari√°veis.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
import sys
from datetime import datetime
from scipy import stats

# Adicionar o diret√≥rio pai ao path para importa√ß√µes
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import RAW_DATA_FILE, CLEAN_DATA_FILE, RESULTS_DIR
from src.id_mapping_utils import IDMappingUtils

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
warnings.filterwarnings('ignore')

# Criar diret√≥rio de resultados se n√£o existir
os.makedirs(RESULTS_DIR, exist_ok=True)

class ExploratoryDataAnalysis:
    """
    Classe para an√°lise explorat√≥ria abrangente dos dados
    
    Esta classe implementa uma an√°lise explorat√≥ria completa com:
    - Visualiza√ß√µes gr√°ficas interativas
    - Estat√≠sticas descritivas detalhadas
    - An√°lise de correla√ß√µes e rela√ß√µes entre vari√°veis
    - Gera√ß√£o de relat√≥rios automatizados
    """
    
    def __init__(self, data_path=None):
        """
        Inicializa a an√°lise explorat√≥ria
        
        Args:
            data_path (str): Caminho para o arquivo de dados. 
                           Por padr√£o usa dados limpos (CLEAN_DATA_FILE)
        """
        # Priorizar dados limpos se dispon√≠veis
        if data_path is None:
            if os.path.exists(CLEAN_DATA_FILE):
                self.data_path = CLEAN_DATA_FILE
                print(f"‚úÖ Usando dados limpos: {CLEAN_DATA_FILE}")
            else:
                self.data_path = RAW_DATA_FILE
                print(f"‚ö†Ô∏è  Dados limpos n√£o encontrados. Usando dados brutos: {RAW_DATA_FILE}")
        else:
            self.data_path = data_path
            
        self.df = None
        self.id_mapper = IDMappingUtils()
        self.results_dir = RESULTS_DIR
        self.figures = []  # Lista para armazenar figuras geradas
        
        # Carregar mapeamentos de IDs
        try:
            self.id_mapper.load_mappings()
        except Exception as e:
            print(f"Aviso: N√£o foi poss√≠vel carregar mapeamentos de IDs: {e}")
    
    def save_figure(self, fig, filename, dpi=300):
        """Salva figura em alta qualidade"""
        filepath = os.path.join(self.results_dir, f"{filename}.png")
        fig.savefig(filepath, dpi=dpi, bbox_inches='tight', facecolor='white')
        self.figures.append(filepath)
        plt.close(fig)
        print(f"  üìä Gr√°fico salvo: {filename}.png")
        
    def load_data(self):
        """Carrega os dados do arquivo CSV"""
        print(f"Carregando dados de: {self.data_path}")
        self.df = pd.read_csv(self.data_path)
        print(f"Dados carregados. Shape: {self.df.shape}")
        return self.df
    
    def basic_info(self):
        """Exibe informa√ß√µes b√°sicas sobre o dataset"""
        print("\n" + "="*60)
        print("INFORMA√á√ïES B√ÅSICAS DO DATASET")
        print("="*60)
        
        print(f"\nTamanho do dataset: {self.df.shape}")
        print(f"N√∫mero de colunas: {self.df.shape[1]}")
        print(f"N√∫mero de registros: {self.df.shape[0]}")
        print(f"N√∫mero de pacientes √∫nicos: {self.df['patient_nbr'].nunique()}")
        print(f"N√∫mero de encontros: {len(self.df)}")
        
        print(f"\nInforma√ß√µes dos tipos de dados:")
        print(self.df.info())
        
        print(f"\nPrimeiras 5 linhas:")
        print(self.df.head())
        
    def analyze_target_variable(self):
        """Analisa a vari√°vel alvo 'readmitted' com visualiza√ß√µes"""
        print("\n" + "="*60)
        print("AN√ÅLISE DA VARI√ÅVEL ALVO")
        print("="*60)
        
        # Verificar se a coluna 'readmitted' existe
        if 'readmitted' not in self.df.columns:
            print("‚ùå Coluna 'readmitted' n√£o encontrada no dataset!")
            # Tentar encontrar colunas similares
            similar_cols = [col for col in self.df.columns if 'readmit' in col.lower()]
            if similar_cols:
                print(f"Colunas similares encontradas: {similar_cols}")
            return
        
        # Verificar se a coluna 'target' j√° existe (deve vir dos dados limpos)
        if 'target' not in self.df.columns:
            print("‚ö†Ô∏è  Coluna 'target' n√£o encontrada! Verificando se pode ser criada...")
            if 'readmitted' in self.df.columns:
                print("üéØ Criando vari√°vel target a partir de 'readmitted'...")
                self.df['target'] = self.df['readmitted'].apply(lambda x: 1 if x == '<30' else 0)
                print("‚úÖ Vari√°vel target criada temporariamente para an√°lise!")
            else:
                print("‚ùå N√£o foi poss√≠vel criar a vari√°vel target - 'readmitted' n√£o encontrada!")
                return
        else:
            print("‚úÖ Vari√°vel target encontrada nos dados limpos!")
        
        print("\nDistribui√ß√£o da vari√°vel 'readmitted':")
        if 'readmitted' in self.df.columns:
            readmitted_counts = self.df['readmitted'].value_counts()
            print(readmitted_counts)
            print(f"\nDistribui√ß√£o percentual:")
            readmitted_pct = self.df['readmitted'].value_counts(normalize=True) * 100
            print(readmitted_pct.round(2))
        
        print(f"\nüìä Estat√≠sticas da vari√°vel target:")
        print(f"Propor√ß√£o de readmiss√µes em <30 dias: {self.df['target'].mean():.3f}")
        print(f"Total de readmiss√µes em <30 dias: {self.df['target'].sum():,}")
        print(f"Total de casos: {len(self.df):,}")
        
        # Verificar se h√° dados v√°lidos para visualiza√ß√£o
        if readmitted_counts.empty:
            print("‚ö†Ô∏è  Sem dados v√°lidos para visualiza√ß√£o da vari√°vel target")
            return
        
        # Visualiza√ß√µes
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # Gr√°fico de barras - readmitted
        ax1 = axes[0]
        order = ['NO', '>30', '<30']
        # Filtrar apenas valores que existem nos dados
        available_order = [val for val in order if val in readmitted_counts.index]
        
        if available_order:
            sns.countplot(data=self.df, x='readmitted', order=available_order, ax=ax1)
            ax1.set_title('Distribui√ß√£o da Vari√°vel Readmitted', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Status de Readmiss√£o')
            ax1.set_ylabel('Contagem')
            
            # Adicionar valores nas barras
            for i, cat in enumerate(available_order):
                if cat in readmitted_counts.index:
                    v = readmitted_counts[cat]
                    pct = readmitted_pct[cat] if cat in readmitted_pct.index else 0
                    ax1.text(i, v + max(readmitted_counts.values)*0.01, f'{v:,}\n({pct:.1f}%)', 
                            ha='center', va='bottom', fontweight='bold')
        else:
            ax1.text(0.5, 0.5, 'Dados insuficientes\npara visualiza√ß√£o', 
                    ha='center', va='center', transform=ax1.transAxes)
        
        # Gr√°fico de pizza - target bin√°rio
        ax2 = axes[1]
        target_counts = self.df['target'].value_counts()
        if len(target_counts) > 1:
            labels = ['N√£o Readmitido (<30d)', 'Readmitido (<30d)']
            colors = ['lightblue', 'salmon']
            wedges, texts, autotexts = ax2.pie(target_counts.values, labels=labels, 
                                              autopct='%1.1f%%', colors=colors, startangle=90)
            ax2.set_title('Distribui√ß√£o da Vari√°vel Target\n(Readmiss√£o <30 dias)', 
                         fontsize=14, fontweight='bold')
        else:
            ax2.text(0.5, 0.5, 'Dados de target\ninsuficientes', 
                    ha='center', va='center', transform=ax2.transAxes)
        
        # Gr√°fico de barras horizontais - compara√ß√£o
        ax3 = axes[2]
        comparison_data = pd.DataFrame({
            'Categoria': ['Total de Casos', 'Readmiss√µes <30d', 'Readmiss√µes >30d', 'N√£o Readmitidos'],
            'Valor': [len(self.df), 
                     (self.df['readmitted'] == '<30').sum(),
                     (self.df['readmitted'] == '>30').sum(),
                     (self.df['readmitted'] == 'NO').sum()]
        })
        
        bars = ax3.barh(comparison_data['Categoria'], comparison_data['Valor'], 
                       color=['darkblue', 'red', 'orange', 'green'])
        ax3.set_title('Compara√ß√£o de Categorias', fontsize=14, fontweight='bold')
        ax3.set_xlabel('N√∫mero de Casos')
        
        # Adicionar valores nas barras
        for i, (bar, value) in enumerate(zip(bars, comparison_data['Valor'])):
            ax3.text(value + max(comparison_data['Valor'])*0.01, i, f'{value:,}', 
                    va='center', fontweight='bold')
        
        plt.tight_layout()
        self.save_figure(fig, 'target_variable_analysis')
        
        # Estat√≠sticas detalhadas
        print(f"\nüìä ESTAT√çSTICAS DETALHADAS:")
        print(f"  ‚Ä¢ Taxa de readmiss√£o geral: {((self.df['readmitted'] != 'NO').mean() * 100):.2f}%")
        print(f"  ‚Ä¢ Taxa de readmiss√£o <30 dias: {(self.df['target'].mean() * 100):.2f}%")
        print(f"  ‚Ä¢ Taxa de readmiss√£o >30 dias: {((self.df['readmitted'] == '>30').mean() * 100):.2f}%")
        
        # Verificar se h√° dados para calcular a raz√£o
        readmit_30_count = (self.df['readmitted'] == '<30').sum()
        readmit_gt30_count = (self.df['readmitted'] == '>30').sum()
        if readmit_gt30_count > 0:
            ratio = readmit_30_count / readmit_gt30_count
            print(f"  ‚Ä¢ Raz√£o readmiss√£o <30d / >30d: {ratio:.2f}")
        else:
            print(f"  ‚Ä¢ Raz√£o readmiss√£o <30d / >30d: N/A (sem readmiss√µes >30d)")
    
    def analyze_missing_data(self):
        """Analisa dados faltantes no dataset com visualiza√ß√µes"""
        print("\n" + "="*60)
        print("AN√ÅLISE DE DADOS FALTANTES")
        print("="*60)
        
        # Calcular porcentagem de dados faltantes por coluna
        missing_data = pd.DataFrame({
            'Missing_Count': self.df.isnull().sum(),
            'Missing_Percentage': (self.df.isnull().sum() / len(self.df)) * 100
        })
        
        # Filtrar apenas colunas com dados faltantes
        missing_data = missing_data[missing_data['Missing_Count'] > 0]
        missing_data = missing_data.sort_values('Missing_Percentage', ascending=False)
        
        print(f"\nColunas com dados faltantes ({len(missing_data)} de {len(self.df.columns)}):")
        for col, row in missing_data.head(10).iterrows():
            print(f"  {col}: {row['Missing_Count']:,} ({row['Missing_Percentage']:.1f}%)")
        
        # Analisar valores especiais ('?', 'NULL', etc.)
        print(f"\nAn√°lise de valores especiais:")
        special_values = ['?', 'NULL', 'null', 'None', '']
        special_counts = {}
        for value in special_values:
            count = (self.df == value).sum().sum()
            if count > 0:
                special_counts[value] = count
                print(f"  Valores '{value}': {count:,}")
        
        # An√°lise especial para valores '?' (comum neste dataset)
        if '?' in self.df.values:
            print(f"\nüîç An√°lise detalhada de valores '?':")
            for col in self.df.columns:
                question_count = (self.df[col] == '?').sum()
                if question_count > 0:
                    pct = (question_count / len(self.df)) * 100
                    print(f"  {col}: {question_count:,} ({pct:.1f}%)")
        
        # Visualiza√ß√µes
        if len(missing_data) > 0:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            
            # Mapa de calor de dados faltantes
            ax1 = axes[0, 0]
            # Selecionar colunas com mais dados faltantes para visualiza√ß√£o
            cols_to_show = missing_data.head(15).index.tolist()
            missing_matrix = self.df[cols_to_show].isnull()
            sns.heatmap(missing_matrix, cbar=True, cmap='viridis', ax=ax1)
            ax1.set_title('Mapa de Calor - Dados Faltantes\n(Top 15 colunas)', 
                         fontsize=14, fontweight='bold')
            ax1.set_xlabel('Colunas')
            ax1.set_ylabel('Registros (amostra)')
            
            # Gr√°fico de barras - porcentagem de dados faltantes
            ax2 = axes[0, 1]
            top_missing = missing_data.head(15)
            bars = ax2.barh(range(len(top_missing)), top_missing['Missing_Percentage'], 
                           color='coral')
            ax2.set_yticks(range(len(top_missing)))
            ax2.set_yticklabels(top_missing.index, fontsize=10)
            ax2.set_xlabel('Porcentagem de Dados Faltantes (%)')
            ax2.set_title('Top 15 Colunas com Dados Faltantes', 
                         fontsize=14, fontweight='bold')
            
            # Adicionar valores nas barras
            for i, (bar, value) in enumerate(zip(bars, top_missing['Missing_Percentage'])):
                ax2.text(value + 0.5, i, f'{value:.1f}%', va='center', fontsize=9)
            
            # Distribui√ß√£o geral de missingness
            ax3 = axes[1, 0]
            missingness_per_row = self.df.isnull().sum(axis=1)
            ax3.hist(missingness_per_row, bins=50, color='skyblue', alpha=0.7, edgecolor='black')
            ax3.set_xlabel('N√∫mero de Valores Faltantes por Registro')
            ax3.set_ylabel('Frequ√™ncia')
            ax3.set_title('Distribui√ß√£o de Valores Faltantes por Registro', 
                         fontsize=14, fontweight='bold')
            ax3.axvline(missingness_per_row.mean(), color='red', linestyle='--', 
                       label=f'M√©dia: {missingness_per_row.mean():.1f}')
            ax3.legend()
            
            # Padr√µes de dados faltantes (combina√ß√µes)
            ax4 = axes[1, 1]
            if len(cols_to_show) >= 3:
                # Analisar padr√µes de missing data para as top 5 colunas
                top_5_cols = cols_to_show[:5]
                missing_patterns = self.df[top_5_cols].isnull().astype(int)
                pattern_counts = missing_patterns.groupby(top_5_cols).size().sort_values(ascending=False).head(10)
                
                if len(pattern_counts) > 1:
                    ax4.bar(range(len(pattern_counts)), pattern_counts.values, color='lightgreen')
                    ax4.set_xlabel('Padr√µes de Dados Faltantes (Top 10)')
                    ax4.set_ylabel('Frequ√™ncia')
                    ax4.set_title('Padr√µes de Combina√ß√£o\nDados Faltantes (Top 5 colunas)', 
                                 fontsize=14, fontweight='bold')
                    ax4.set_xticks(range(len(pattern_counts)))
                    ax4.set_xticklabels([f'P{i+1}' for i in range(len(pattern_counts))], rotation=45)
                else:
                    ax4.text(0.5, 0.5, 'Padr√µes insuficientes\npara an√°lise', 
                            ha='center', va='center', transform=ax4.transAxes, fontsize=12)
                    ax4.set_title('Padr√µes de Dados Faltantes', fontsize=14, fontweight='bold')
            else:
                ax4.text(0.5, 0.5, 'Dados insuficientes\npara an√°lise de padr√µes', 
                        ha='center', va='center', transform=ax4.transAxes, fontsize=12)
                ax4.set_title('Padr√µes de Dados Faltantes', fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            self.save_figure(fig, 'missing_data_analysis')
        
        # Estat√≠sticas detalhadas
        print(f"\nüìä ESTAT√çSTICAS DE DADOS FALTANTES:")
        total_cells = len(self.df) * len(self.df.columns)
        total_missing = self.df.isnull().sum().sum()
        print(f"  ‚Ä¢ Total de c√©lulas: {total_cells:,}")
        print(f"  ‚Ä¢ Total de valores faltantes: {total_missing:,}")
        print(f"  ‚Ä¢ Porcentagem geral de missing: {(total_missing/total_cells)*100:.2f}%")
        print(f"  ‚Ä¢ Registros completamente preenchidos: {len(self.df.dropna()):,} ({(len(self.df.dropna())/len(self.df))*100:.1f}%)")
        print(f"  ‚Ä¢ Colunas sem dados faltantes: {len(self.df.columns) - len(missing_data)}")
        
        if special_counts:
            print(f"  ‚Ä¢ Total de valores especiais: {sum(special_counts.values()):,}")
    
    def analyze_demographic_data(self):
        """Analisa dados demogr√°ficos com visualiza√ß√µes"""
        print("\n" + "="*60)
        print("AN√ÅLISE DE DADOS DEMOGR√ÅFICOS")
        print("="*60)
        
        # Preparar dados demogr√°ficos
        demographic_cols = ['age', 'gender', 'race']
        available_cols = [col for col in demographic_cols if col in self.df.columns]
        
        if not available_cols:
            print("‚ö†Ô∏è  Colunas demogr√°ficas n√£o encontradas no dataset.")
            print("Colunas dispon√≠veis:", list(self.df.columns)[:10], "...")
            return
        
        # Criar subplots baseado nas colunas dispon√≠veis
        n_cols = min(len(available_cols), 3)  # M√°ximo de 3 colunas para visualiza√ß√£o
        fig, axes = plt.subplots(2, n_cols, figsize=(6*n_cols, 12))
        if n_cols == 1:
            axes = axes.reshape(-1, 1)
        elif n_cols == 2:
            axes = axes.reshape(2, 2)
        
        col_idx = 0
        
        # Processar apenas as primeiras 3 colunas demogr√°ficas
        cols_to_process = available_cols[:3]
        
        # An√°lise de idade
        if 'age' in cols_to_process and col_idx < n_cols:
            print(f"\nDistribui√ß√£o por faixa et√°ria:")
            age_counts = self.df['age'].value_counts().sort_index()
            age_target = self.df.groupby('age')['target'].agg(['count', 'mean']).round(3)
            age_target.columns = ['Total', 'Taxa_Readmissao']
            
            for age_range, count in age_counts.items():
                pct = (count / len(self.df)) * 100
                readmission_rate = age_target.loc[age_range, 'Taxa_Readmissao'] * 100
                print(f"  {age_range}: {count:,} ({pct:.1f}%) - Taxa readmiss√£o: {readmission_rate:.1f}%")
            
            # Gr√°fico de barras - distribui√ß√£o por idade
            ax1 = axes[0, col_idx]
            bars1 = ax1.bar(range(len(age_counts)), age_counts.values, color='lightblue', alpha=0.8)
            ax1.set_title('Distribui√ß√£o por Faixa Et√°ria', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Faixa Et√°ria')
            ax1.set_ylabel('N√∫mero de Pacientes')
            ax1.set_xticks(range(len(age_counts)))
            ax1.set_xticklabels(age_counts.index, rotation=45)
            
            # Adicionar valores nas barras
            for i, v in enumerate(age_counts.values):
                ax1.text(i, v + max(age_counts.values)*0.01, f'{v:,}', 
                        ha='center', va='bottom', fontsize=10)
            
            # Gr√°fico de linha - taxa de readmiss√£o por idade
            ax2 = axes[1, col_idx]
            ax2.plot(range(len(age_target)), age_target['Taxa_Readmissao'] * 100, 
                    marker='o', linewidth=2, markersize=8, color='red')
            ax2.set_title('Taxa de Readmiss√£o por Faixa Et√°ria', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Faixa Et√°ria')
            ax2.set_ylabel('Taxa de Readmiss√£o (%)')
            ax2.set_xticks(range(len(age_target)))
            ax2.set_xticklabels(age_target.index, rotation=45)
            ax2.grid(True, alpha=0.3)
            
            col_idx += 1
        
        # An√°lise de g√™nero
        if 'gender' in cols_to_process and col_idx < n_cols:
            print(f"\nDistribui√ß√£o por g√™nero:")
            gender_counts = self.df['gender'].value_counts()
            gender_target = self.df.groupby('gender')['target'].agg(['count', 'mean']).round(3)
            gender_target.columns = ['Total', 'Taxa_Readmissao']
            
            for gender, count in gender_counts.items():
                pct = (count / len(self.df)) * 100
                if gender in gender_target.index:
                    readmission_rate = gender_target.loc[gender, 'Taxa_Readmissao'] * 100
                    print(f"  {gender}: {count:,} ({pct:.1f}%) - Taxa readmiss√£o: {readmission_rate:.1f}%")
                else:
                    print(f"  {gender}: {count:,} ({pct:.1f}%)")
            
            # Gr√°fico de pizza - distribui√ß√£o por g√™nero
            ax1 = axes[0, col_idx]
            colors = ['lightcoral', 'lightskyblue', 'lightgreen', 'gold'][:len(gender_counts)]
            wedges, texts, autotexts = ax1.pie(gender_counts.values, labels=gender_counts.index, 
                                              autopct='%1.1f%%', colors=colors, startangle=90)
            ax1.set_title('Distribui√ß√£o por G√™nero', fontsize=14, fontweight='bold')
            
            # Gr√°fico de barras - taxa de readmiss√£o por g√™nero
            ax2 = axes[1, col_idx]
            valid_genders = [g for g in gender_counts.index if g in gender_target.index]
            if valid_genders:
                bars2 = ax2.bar(valid_genders, 
                               [gender_target.loc[g, 'Taxa_Readmissao'] * 100 for g in valid_genders],
                               color=['lightcoral', 'lightskyblue', 'lightgreen'][:len(valid_genders)])
                ax2.set_title('Taxa de Readmiss√£o por G√™nero', fontsize=14, fontweight='bold')
                ax2.set_xlabel('G√™nero')
                ax2.set_ylabel('Taxa de Readmiss√£o (%)')
                
                # Adicionar valores nas barras
                for i, g in enumerate(valid_genders):
                    v = gender_target.loc[g, 'Taxa_Readmissao'] * 100
                    ax2.text(i, v + 0.2, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')
            
            col_idx += 1
        
        # An√°lise de ra√ßa
        if 'race' in cols_to_process and col_idx < n_cols:
            print(f"\nDistribui√ß√£o por ra√ßa:")
            race_counts = self.df['race'].value_counts()
            race_target = self.df.groupby('race')['target'].agg(['count', 'mean']).round(3)
            race_target.columns = ['Total', 'Taxa_Readmissao']
            
            for race, count in race_counts.head(10).items():
                pct = (count / len(self.df)) * 100
                if race in race_target.index:
                    readmission_rate = race_target.loc[race, 'Taxa_Readmissao'] * 100
                    print(f"  {race}: {count:,} ({pct:.1f}%) - Taxa readmiss√£o: {readmission_rate:.1f}%")
                else:
                    print(f"  {race}: {count:,} ({pct:.1f}%)")
            
            # Gr√°fico de barras horizontais - distribui√ß√£o por ra√ßa (top 10)
            ax1 = axes[0, col_idx]
            top_races = race_counts.head(10)
            bars1 = ax1.barh(range(len(top_races)), top_races.values, color='lightgreen')
            ax1.set_title('Distribui√ß√£o por Ra√ßa (Top 10)', fontsize=14, fontweight='bold')
            ax1.set_xlabel('N√∫mero de Pacientes')
            ax1.set_yticks(range(len(top_races)))
            ax1.set_yticklabels(top_races.index, fontsize=10)
            
            # Adicionar valores nas barras
            for i, v in enumerate(top_races.values):
                ax1.text(v + max(top_races.values)*0.01, i, f'{v:,}', 
                        va='center', ha='left', fontsize=9)
            
            # Gr√°fico de barras - taxa de readmiss√£o por ra√ßa (top 10)
            ax2 = axes[1, col_idx]
            valid_races = [r for r in top_races.index if r in race_target.index]
            if valid_races:
                readmission_rates = [race_target.loc[r, 'Taxa_Readmissao'] * 100 for r in valid_races]
                bars2 = ax2.barh(range(len(valid_races)), readmission_rates, color='salmon')
                ax2.set_title('Taxa de Readmiss√£o por Ra√ßa (Top 10)', fontsize=14, fontweight='bold')
                ax2.set_xlabel('Taxa de Readmiss√£o (%)')
                ax2.set_yticks(range(len(valid_races)))
                ax2.set_yticklabels(valid_races, fontsize=10)
                
                # Adicionar valores nas barras
                for i, v in enumerate(readmission_rates):
                    ax2.text(v + 0.1, i, f'{v:.1f}%', va='center', ha='left', fontsize=9)
        
        plt.tight_layout()
        self.save_figure(fig, 'demographic_analysis')
        
        # Estat√≠sticas detalhadas
        print(f"\nüìä ESTAT√çSTICAS DEMOGR√ÅFICAS:")
        if 'age' in self.df.columns:
            age_counts = self.df['age'].value_counts().sort_index()
            age_stats = self.df.groupby('age')['target'].agg(['count', 'mean'])
            most_common_age = age_counts.index[0]
            highest_risk_age = age_stats['mean'].idxmax()
            print(f"  ‚Ä¢ Faixa et√°ria mais comum: {most_common_age}")
            print(f"  ‚Ä¢ Faixa et√°ria com maior risco: {highest_risk_age} ({age_stats.loc[highest_risk_age, 'mean']*100:.1f}%)")
        
        if 'gender' in self.df.columns:
            gender_counts = self.df['gender'].value_counts()
            gender_stats = self.df.groupby('gender')['target'].agg(['count', 'mean'])
            if len(gender_stats) > 1:
                most_common_gender = gender_counts.index[0]
                highest_risk_gender = gender_stats['mean'].idxmax()
                print(f"  ‚Ä¢ G√™nero mais comum: {most_common_gender}")
                print(f"  ‚Ä¢ G√™nero com maior risco: {highest_risk_gender} ({gender_stats.loc[highest_risk_gender, 'mean']*100:.1f}%)")
        
        if 'race' in self.df.columns:
            race_counts = self.df['race'].value_counts()
            race_stats = self.df.groupby('race')['target'].agg(['count', 'mean'])
            most_common_race = race_counts.index[0]
            highest_risk_race = race_stats['mean'].idxmax()
            print(f"  ‚Ä¢ Ra√ßa mais comum: {most_common_race}")
            print(f"  ‚Ä¢ Ra√ßa com maior risco: {highest_risk_race} ({race_stats.loc[highest_risk_race, 'mean']*100:.1f}%)")
    
    def analyze_medical_data(self):
        """Analisa dados m√©dicos com visualiza√ß√µes e correla√ß√µes"""
        print("\n" + "="*60)
        print("AN√ÅLISE DE DADOS M√âDICOS")
        print("="*60)
        
        # An√°lise de especialidade m√©dica
        if 'medical_specialty' in self.df.columns:
            print(f"\nTop 10 especialidades m√©dicas:")
            specialty_counts = self.df['medical_specialty'].value_counts()
            specialty_target = self.df.groupby('medical_specialty')['target'].agg(['count', 'mean']).round(3)
            specialty_target.columns = ['Total', 'Taxa_Readmissao']
            
            for specialty, count in specialty_counts.head(10).items():
                pct = (count / len(self.df)) * 100
                if specialty in specialty_target.index:
                    readmission_rate = specialty_target.loc[specialty, 'Taxa_Readmissao'] * 100
                    print(f"  {specialty}: {count:,} ({pct:.1f}%) - Taxa: {readmission_rate:.1f}%")
                else:
                    print(f"  {specialty}: {count:,} ({pct:.1f}%)")
        
        # An√°lise de vari√°veis num√©ricas
        numeric_cols = ['num_lab_procedures', 'num_procedures', 'num_medications', 
                       'number_outpatient', 'number_emergency', 'number_inpatient',
                       'time_in_hospital', 'number_diagnoses']
        
        available_numeric = [col for col in numeric_cols if col in self.df.columns]
        
        if available_numeric:
            print(f"\nüìä ESTAT√çSTICAS DAS VARI√ÅVEIS NUM√âRICAS:")
            stats_df = pd.DataFrame()
            
            for col in available_numeric:
                stats = {
                    'M√©dia': self.df[col].mean(),
                    'Mediana': self.df[col].median(),
                    'Moda': self.df[col].mode()[0] if len(self.df[col].mode()) > 0 else np.nan,
                    'Desvio_Padr√£o': self.df[col].std(),
                    'M√≠nimo': self.df[col].min(),
                    'M√°ximo': self.df[col].max(),
                    'Q1': self.df[col].quantile(0.25),
                    'Q3': self.df[col].quantile(0.75),
                    'Correla√ß√£o_Target': self.df[col].corr(self.df['target'])
                }
                stats_df[col] = stats
                
                print(f"\n{col}:")
                for stat_name, stat_value in stats.items():
                    if stat_name == 'Correla√ß√£o_Target':
                        print(f"  {stat_name}: {stat_value:.3f}")
                    else:
                        print(f"  {stat_name}: {stat_value:.2f}")
            
            # Visualiza√ß√µes
            n_numeric = len(available_numeric)
            fig = plt.figure(figsize=(20, 16))
            
            # 1. Histogramas das vari√°veis num√©ricas
            for i, col in enumerate(available_numeric):
                ax = plt.subplot(4, 4, i + 1)
                
                # Histograma
                self.df[col].hist(bins=30, alpha=0.7, color='skyblue', edgecolor='black', ax=ax)
                ax.axvline(self.df[col].mean(), color='red', linestyle='--', 
                          label=f'M√©dia: {self.df[col].mean():.1f}')
                ax.axvline(self.df[col].median(), color='orange', linestyle='--', 
                          label=f'Mediana: {self.df[col].median():.1f}')
                
                ax.set_title(f'{col}', fontsize=12, fontweight='bold')
                ax.set_xlabel('Valor')
                ax.set_ylabel('Frequ√™ncia')
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)
            
            # Ajustar layout dos histogramas
            plt.tight_layout()
            self.save_figure(fig, 'medical_data_histograms')
            
            # 2. Mapa de calor de correla√ß√µes
            fig, axes = plt.subplots(1, 2, figsize=(16, 8))
            
            # Correla√ß√µes entre vari√°veis num√©ricas
            corr_matrix = self.df[available_numeric].corr()
            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
            
            ax1 = axes[0]
            sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                       square=True, ax=ax1, cbar_kws={"shrink": .8})
            ax1.set_title('Correla√ß√µes entre Vari√°veis Num√©ricas', fontsize=14, fontweight='bold')
            
            # Correla√ß√µes com a vari√°vel target
            target_corr = self.df[available_numeric + ['target']].corr()['target'].drop('target').sort_values()
            
            ax2 = axes[1]
            colors = ['red' if x < 0 else 'green' for x in target_corr.values]
            bars = ax2.barh(range(len(target_corr)), target_corr.values, color=colors, alpha=0.7)
            ax2.set_yticks(range(len(target_corr)))
            ax2.set_yticklabels(target_corr.index, fontsize=10)
            ax2.set_xlabel('Correla√ß√£o com Target')
            ax2.set_title('Correla√ß√£o das Vari√°veis com Readmiss√£o', fontsize=14, fontweight='bold')
            ax2.axvline(0, color='black', linestyle='-', linewidth=0.8)
            ax2.grid(True, alpha=0.3)
            
            # Adicionar valores nas barras
            for i, v in enumerate(target_corr.values):
                ax2.text(v + 0.001 if v >= 0 else v - 0.001, i, f'{v:.3f}', 
                        va='center', ha='left' if v >= 0 else 'right', fontsize=9)
            
            plt.tight_layout()
            self.save_figure(fig, 'medical_data_correlations')
            
            # 3. Box plots comparando readmitidos vs n√£o readmitidos
            fig, axes = plt.subplots(2, 4, figsize=(20, 12))
            axes = axes.flatten()
            
            for i, col in enumerate(available_numeric):
                if i < len(axes):
                    ax = axes[i]
                    
                    # Box plot
                    self.df.boxplot(column=col, by='target', ax=ax)
                    ax.set_title(f'{col}\nReadmitido vs N√£o Readmitido')
                    ax.set_xlabel('Target (0: N√£o, 1: Sim)')
                    ax.set_ylabel(col)
                    
                    # Estat√≠sticas comparativas
                    non_readmitted = self.df[self.df['target'] == 0][col]
                    readmitted = self.df[self.df['target'] == 1][col]
                    
                    # Teste t para diferen√ßa significativa
                    try:
                        t_stat, p_value = stats.ttest_ind(non_readmitted.dropna(), readmitted.dropna())
                        significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else ""
                        ax.text(0.02, 0.98, f'p-value: {p_value:.3f}{significance}', 
                               transform=ax.transAxes, fontsize=8, verticalalignment='top',
                               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
                    except:
                        pass
            
            # Remover subplots vazios
            for j in range(i+1, len(axes)):
                axes[j].remove()
            
            plt.suptitle('Compara√ß√£o de Vari√°veis M√©dicas\nReadmitidos vs N√£o Readmitidos', 
                        fontsize=16, fontweight='bold', y=0.98)
            plt.tight_layout()
            self.save_figure(fig, 'medical_data_boxplots')
        
        # An√°lise de tempo de interna√ß√£o se dispon√≠vel
        if 'time_in_hospital' in self.df.columns:
            print(f"\nüè• AN√ÅLISE DE TEMPO DE INTERNA√á√ÉO:")
            time_stats = self.df.groupby('time_in_hospital')['target'].agg(['count', 'mean']).round(3)
            time_stats.columns = ['Total_Casos', 'Taxa_Readmissao']
            
            print(f"  ‚Ä¢ Tempo m√©dio de interna√ß√£o: {self.df['time_in_hospital'].mean():.1f} dias")
            print(f"  ‚Ä¢ Tempo mediano de interna√ß√£o: {self.df['time_in_hospital'].median():.1f} dias")
            print(f"  ‚Ä¢ Interna√ß√µes mais longas t√™m maior risco de readmiss√£o:")
            
            # Mostrar estat√≠sticas por tempo de interna√ß√£o
            for time_days in sorted(self.df['time_in_hospital'].unique())[:10]:
                if time_days in time_stats.index:
                    total = time_stats.loc[time_days, 'Total_Casos']
                    rate = time_stats.loc[time_days, 'Taxa_Readmissao'] * 100
                    print(f"    {time_days} dias: {total} casos - Taxa: {rate:.1f}%")
        
        # Estat√≠sticas detalhadas
        print(f"\nüìä INSIGHTS M√âDICOS:")
        if available_numeric:
            # Vari√°vel mais correlacionada com readmiss√£o
            target_corr = self.df[available_numeric].corrwith(self.df['target']).abs()
            most_correlated = target_corr.idxmax()
            correlation_value = self.df[most_correlated].corr(self.df['target'])
            print(f"  ‚Ä¢ Vari√°vel mais correlacionada com readmiss√£o: {most_correlated} (r={correlation_value:.3f})")
            
            # M√©dias comparativas
            for col in available_numeric[:5]:  # Top 5 vari√°veis
                mean_no_readmit = self.df[self.df['target'] == 0][col].mean()
                mean_readmit = self.df[self.df['target'] == 1][col].mean()
                diff_pct = ((mean_readmit - mean_no_readmit) / mean_no_readmit) * 100
                print(f"  ‚Ä¢ {col}: N√£o readmitidos={mean_no_readmit:.1f}, Readmitidos={mean_readmit:.1f} ({diff_pct:+.1f}%)")
    
    def analyze_id_mappings(self):
        """Analisa dados com mapeamentos de IDs aplicados"""
        print("\n" + "="*60)
        print("AN√ÅLISE COM MAPEAMENTOS DE IDS")
        print("="*60)
        
        if self.id_mapper is None or not hasattr(self.id_mapper, 'mappings') or not self.id_mapper.mappings:
            print("‚ö†Ô∏è  Mapeamentos de IDs n√£o dispon√≠veis.")
            print("Verificando se arquivo de mapeamento existe...")
            try:
                from src.config import MAPPING_FILE
                if os.path.exists(MAPPING_FILE):
                    print(f"‚úÖ Arquivo encontrado: {MAPPING_FILE}")
                    print("üí° Voc√™ pode carregar os mapeamentos manualmente.")
                else:
                    print(f"‚ùå Arquivo n√£o encontrado: {MAPPING_FILE}")
            except:
                print("‚ùå N√£o foi poss√≠vel verificar o arquivo de mapeamento.")
            return
        
        try:
            # Aplicar mapeamentos temporariamente para an√°lise
            df_with_mappings = self.id_mapper.apply_mappings_to_dataframe(self.df.copy())
            
            # Analisar admission_type
            if 'admission_type_desc' in df_with_mappings.columns:
                print("\nüè• TIPO DE ADMISS√ÉO:")
                admission_analysis = df_with_mappings.groupby('admission_type_desc').agg({
                    'target': ['count', 'mean']
                }).round(3)
                admission_analysis.columns = ['Total_Casos', 'Taxa_Readmissao']
                print(admission_analysis.sort_values('Total_Casos', ascending=False))
            
            # Analisar discharge_disposition
            if 'discharge_disposition_desc' in df_with_mappings.columns:
                print("\nüö™ DISPOSI√á√ÉO DE ALTA:")
                discharge_analysis = df_with_mappings.groupby('discharge_disposition_desc').agg({
                    'target': ['count', 'mean']
                }).round(3)
                discharge_analysis.columns = ['Total_Casos', 'Taxa_Readmissao']
                # Mostrar apenas os 10 mais comuns
                top_discharges = discharge_analysis.sort_values('Total_Casos', ascending=False).head(10)
                print(top_discharges)
            
            # Analisar admission_source
            if 'admission_source_desc' in df_with_mappings.columns:
                print("\nüìç FONTE DE ADMISS√ÉO:")
                source_analysis = df_with_mappings.groupby('admission_source_desc').agg({
                    'target': ['count', 'mean']
                }).round(3)
                source_analysis.columns = ['Total_Casos', 'Taxa_Readmissao']
                # Mostrar apenas os 10 mais comuns
                top_sources = source_analysis.sort_values('Total_Casos', ascending=False).head(10)
                print(top_sources)
            
            # An√°lise cruzada dos mapeamentos
            if all(col in df_with_mappings.columns for col in ['admission_type_desc', 'discharge_disposition_desc']):
                print("\nüìä AN√ÅLISE CRUZADA - TIPO DE ADMISS√ÉO x DISPOSI√á√ÉO DE ALTA:")
                cross_analysis = pd.crosstab(
                    df_with_mappings['admission_type_desc'],
                    df_with_mappings['discharge_disposition_desc'],
                    margins=True
                )
                print(cross_analysis.iloc[:5, :5])  # Mostrar apenas uma amostra
                
        except Exception as e:
            print(f"‚ùå Erro ao aplicar mapeamentos de IDs: {str(e)}")
            print("üí° Continuando an√°lise sem mapeamentos...")
    
    def analyze_medication_data(self):
        """Analisa dados de medicamentos com visualiza√ß√µes e estat√≠sticas"""
        print("\n" + "="*60)
        print("AN√ÅLISE DE DADOS DE MEDICAMENTOS")
        print("="*60)
        
        # Identificar colunas de medicamentos
        med_columns = [col for col in self.df.columns if any(med in col.lower() for med in 
                      ['insulin', 'metformin', 'glyburide', 'glipizide', 'glimepiride', 
                       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',
                       'tolazamide', 'examide', 'citoglipton', 'glyburide-metformin',
                       'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone',
                       'metformin-pioglitazone'])]
        
        if med_columns:
            print(f"\nüíä Medicamentos analisados: {len(med_columns)}")
            
            # An√°lise detalhada dos principais medicamentos
            med_summary = []
            for med_col in med_columns:
                if med_col in self.df.columns:
                    value_counts = self.df[med_col].value_counts()
                    total_prescribed = len(self.df) - (self.df[med_col] == 'No').sum() if 'No' in value_counts else len(self.df)
                    prescription_rate = (total_prescribed / len(self.df)) * 100
                    
                    print(f"\n{med_col}:")
                    for value, count in value_counts.head(5).items():
                        pct = (count / len(self.df)) * 100
                        print(f"  {value}: {count:,} ({pct:.1f}%)")
                    
                    # An√°lise de impacto na readmiss√£o
                    if 'target' in self.df.columns and total_prescribed > 0:
                        prescribed_patients = self.df[self.df[med_col] != 'No'] if 'No' in value_counts else self.df
                        if len(prescribed_patients) > 0:
                            readmission_rate = prescribed_patients['target'].mean() * 100
                            print(f"  Taxa de readmiss√£o para pacientes com {med_col}: {readmission_rate:.1f}%")
                            
                            med_summary.append({
                                'Medicamento': med_col,
                                'Taxa_Prescricao': prescription_rate,
                                'Taxa_Readmissao': readmission_rate,
                                'Total_Pacientes': total_prescribed
                            })
            
            # Resumo dos medicamentos
            if med_summary:
                med_df = pd.DataFrame(med_summary)
                print(f"\nüìä RESUMO DOS MEDICAMENTOS:")
                print(med_df.sort_values('Taxa_Prescricao', ascending=False).to_string(index=False, float_format='%.1f'))
                
                # Visualiza√ß√£o se houver dados suficientes
                if len(med_summary) >= 3:
                    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
                    
                    # Gr√°fico 1: Taxa de prescri√ß√£o
                    ax1 = axes[0]
                    top_meds = med_df.nlargest(10, 'Taxa_Prescricao')
                    bars1 = ax1.barh(range(len(top_meds)), top_meds['Taxa_Prescricao'], color='lightblue')
                    ax1.set_yticks(range(len(top_meds)))
                    ax1.set_yticklabels([med.replace('_', ' ') for med in top_meds['Medicamento']], fontsize=10)
                    ax1.set_xlabel('Taxa de Prescri√ß√£o (%)')
                    ax1.set_title('Top 10 Medicamentos por Taxa de Prescri√ß√£o', fontsize=14, fontweight='bold')
                    
                    # Adicionar valores
                    for i, v in enumerate(top_meds['Taxa_Prescricao']):
                        ax1.text(v + 0.5, i, f'{v:.1f}%', va='center', fontsize=9)
                    
                    # Gr√°fico 2: Rela√ß√£o prescri√ß√£o x readmiss√£o
                    ax2 = axes[1]
                    scatter = ax2.scatter(med_df['Taxa_Prescricao'], med_df['Taxa_Readmissao'], 
                                        s=med_df['Total_Pacientes']/50, alpha=0.6, c='coral')
                    ax2.set_xlabel('Taxa de Prescri√ß√£o (%)')
                    ax2.set_ylabel('Taxa de Readmiss√£o (%)')
                    ax2.set_title('Rela√ß√£o entre Prescri√ß√£o e Readmiss√£o\n(Tamanho = n¬∫ pacientes)', 
                                 fontsize=14, fontweight='bold')
                    ax2.grid(True, alpha=0.3)
                    
                    # Adicionar labels para medicamentos importantes
                    for _, row in med_df.iterrows():
                        if row['Taxa_Prescricao'] > 10 or row['Taxa_Readmissao'] > 15:
                            ax2.annotate(row['Medicamento'].replace('_', ' ')[:15], 
                                       (row['Taxa_Prescricao'], row['Taxa_Readmissao']),
                                       xytext=(5, 5), textcoords='offset points', fontsize=8)
                    
                    plt.tight_layout()
                    self.save_figure(fig, 'medication_analysis')
        else:
            print("‚ö†Ô∏è  Nenhuma coluna de medicamento encontrada no dataset.")
        
        # Analisar mudan√ßas na medica√ß√£o
        change_cols = [col for col in self.df.columns if 'change' in col.lower()]
        if change_cols:
            print(f"\nüîÑ AN√ÅLISE DE MUDAN√áAS NA MEDICA√á√ÉO:")
            for col in change_cols:
                if col in self.df.columns:
                    change_counts = self.df[col].value_counts()
                    print(f"\n{col}:")
                    for value, count in change_counts.items():
                        pct = (count / len(self.df)) * 100
                        print(f"  {value}: {count:,} ({pct:.1f}%)")
                    
                    # Impacto na readmiss√£o
                    if 'target' in self.df.columns:
                        for value in change_counts.index:
                            subset = self.df[self.df[col] == value]
                            if len(subset) > 0:
                                readmit_rate = subset['target'].mean() * 100
                                print(f"    Taxa readmiss√£o para '{value}': {readmit_rate:.1f}%")
        else:
            print("‚ö†Ô∏è  Nenhuma coluna de mudan√ßa de medica√ß√£o encontrada.")
        
        # Insights sobre medicamentos
        print(f"\nüí° INSIGHTS SOBRE MEDICAMENTOS:")
        if med_summary:
            most_prescribed = max(med_summary, key=lambda x: x['Taxa_Prescricao'])
            highest_readmit = max(med_summary, key=lambda x: x['Taxa_Readmissao'])
            print(f"  ‚Ä¢ Medicamento mais prescrito: {most_prescribed['Medicamento']} ({most_prescribed['Taxa_Prescricao']:.1f}%)")
            print(f"  ‚Ä¢ Maior taxa de readmiss√£o: {highest_readmit['Medicamento']} ({highest_readmit['Taxa_Readmissao']:.1f}%)")
            
            # Correla√ß√£o entre prescri√ß√£o e readmiss√£o
            prescriptions = [item['Taxa_Prescricao'] for item in med_summary]
            readmissions = [item['Taxa_Readmissao'] for item in med_summary]
            if len(prescriptions) > 2:
                correlation = np.corrcoef(prescriptions, readmissions)[0, 1]
                print(f"  ‚Ä¢ Correla√ß√£o prescri√ß√£o-readmiss√£o: {correlation:.3f}")
        else:
            print("  ‚Ä¢ Dados insuficientes para gerar insights sobre medicamentos.")
    
    def analyze_multivariate_relationships(self):
        """Analisa rela√ß√µes multivariadas entre 3 ou mais vari√°veis"""
        print("\n" + "="*60)
        print("AN√ÅLISE MULTIVARIADA - INTERA√á√ïES ENTRE VARI√ÅVEIS")
        print("="*60)
        
        # Verificar se temos vari√°veis necess√°rias
        required_cols = ['target']
        available_cols = [col for col in required_cols if col in self.df.columns]
        
        if 'target' not in self.df.columns:
            print("‚ö†Ô∏è  Vari√°vel target n√£o encontrada. An√°lise multivariada n√£o pode ser realizada.")
            return
        
        # An√°lise 1: Taxa de readmiss√£o por tempo de interna√ß√£o e ra√ßa
        if all(col in self.df.columns for col in ['time_in_hospital', 'race']):
            print("\nüè• An√°lise: Tempo de Interna√ß√£o √ó Ra√ßa √ó Readmiss√£o")
            
            # Preparar dados para an√°lise
            df_multi = self.df.copy()
            
            # Agrupar ra√ßas menos comuns para simplificar visualiza√ß√£o
            race_counts = df_multi['race'].value_counts()
            top_races = race_counts.head(4).index.tolist()
            df_multi['race_grouped'] = df_multi['race'].apply(
                lambda x: x if x in top_races else 'Other'
            )
            
            # Calcular taxa de readmiss√£o por tempo e ra√ßa
            multivar_stats = df_multi.groupby(['time_in_hospital', 'race_grouped'])['target'].agg(['count', 'mean']).reset_index()
            multivar_stats.columns = ['time_in_hospital', 'race_grouped', 'count', 'readmission_rate']
            
            # Filtrar apenas grupos com pelo menos 10 casos
            multivar_stats = multivar_stats[multivar_stats['count'] >= 10]
            
            if not multivar_stats.empty:
                fig, axes = plt.subplots(1, 2, figsize=(16, 6))
                
                # Gr√°fico 1: Taxa de readmiss√£o por tempo de interna√ß√£o e ra√ßa
                ax1 = axes[0]
                for race in multivar_stats['race_grouped'].unique():
                    race_data = multivar_stats[multivar_stats['race_grouped'] == race]
                    ax1.plot(race_data['time_in_hospital'], race_data['readmission_rate'] * 100, 
                            marker='o', label=race, linewidth=2, markersize=6)
                
                ax1.set_xlabel('Tempo de Interna√ß√£o (dias)')
                ax1.set_ylabel('Taxa de Readmiss√£o (%)')
                ax1.set_title('Taxa de Readmiss√£o vs. Tempo de Interna√ß√£o por Ra√ßa', 
                             fontsize=14, fontweight='bold')
                ax1.legend()
                ax1.grid(True, alpha=0.3)
                
                # Gr√°fico 2: Heatmap de intera√ß√£o
                ax2 = axes[1]
                pivot_data = multivar_stats.pivot(index='race_grouped', 
                                                 columns='time_in_hospital', 
                                                 values='readmission_rate')
                
                sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlOrRd', 
                           ax=ax2, cbar_kws={'label': 'Taxa de Readmiss√£o'})
                ax2.set_title('Mapa de Calor: Readmiss√£o por Tempo √ó Ra√ßa', 
                             fontsize=14, fontweight='bold')
                ax2.set_xlabel('Tempo de Interna√ß√£o (dias)')
                ax2.set_ylabel('Ra√ßa')
                
                plt.tight_layout()
                self.save_figure(fig, 'multivariate_time_race_analysis')
                
                # Insights da an√°lise multivariada
                highest_risk = multivar_stats.loc[multivar_stats['readmission_rate'].idxmax()]
                print(f"  üìä Maior risco identificado:")
                print(f"    ‚Ä¢ Ra√ßa: {highest_risk['race_grouped']}")
                print(f"    ‚Ä¢ Tempo de interna√ß√£o: {highest_risk['time_in_hospital']} dias")
                print(f"    ‚Ä¢ Taxa de readmiss√£o: {highest_risk['readmission_rate']*100:.1f}%")
                print(f"    ‚Ä¢ N√∫mero de casos: {highest_risk['count']}")
        
        # An√°lise 2: Medicamentos √ó Idade √ó Readmiss√£o
        if all(col in self.df.columns for col in ['age', 'insulin']) or all(col in self.df.columns for col in ['age', 'metformin']):
            print("\nüíä An√°lise: Medicamentos √ó Idade √ó Readmiss√£o")
            
            # Escolher medicamento mais comum
            med_col = None
            for potential_med in ['insulin', 'metformin', 'glyburide']:
                if potential_med in self.df.columns:
                    med_col = potential_med
                    break
            
            if med_col:
                # An√°lise de medicamento por idade
                med_age_stats = self.df.groupby(['age', med_col])['target'].agg(['count', 'mean']).reset_index()
                med_age_stats.columns = ['age', med_col, 'count', 'readmission_rate']
                
                # Filtrar grupos com pelo menos 20 casos
                med_age_stats = med_age_stats[med_age_stats['count'] >= 20]
                
                if not med_age_stats.empty:
                    fig, ax = plt.subplots(1, 1, figsize=(12, 6))
                    
                    # Gr√°fico de linhas por status do medicamento
                    for med_status in med_age_stats[med_col].unique():
                        if med_status != '?':  # Excluir valores missing
                            status_data = med_age_stats[med_age_stats[med_col] == med_status]
                            ax.plot(status_data['age'], status_data['readmission_rate'] * 100, 
                                   marker='o', label=f'{med_col}: {med_status}', 
                                   linewidth=2, markersize=6)
                    
                    ax.set_xlabel('Faixa Et√°ria')
                    ax.set_ylabel('Taxa de Readmiss√£o (%)')
                    ax.set_title(f'Taxa de Readmiss√£o por Idade e Status de {med_col.title()}', 
                                fontsize=14, fontweight='bold')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    plt.xticks(rotation=45)
                    plt.tight_layout()
                    
                    self.save_figure(fig, f'multivariate_age_{med_col}_analysis')
                    
                    print(f"  üìä Insights para {med_col}:")
                    for med_status in med_age_stats[med_col].unique():
                        if med_status != '?':
                            status_data = med_age_stats[med_age_stats[med_col] == med_status]
                            if not status_data.empty:
                                avg_risk = status_data['readmission_rate'].mean() * 100
                                print(f"    ‚Ä¢ {med_status}: Taxa m√©dia de readmiss√£o = {avg_risk:.1f}%")
        
        # An√°lise 3: G√™nero √ó Specialty √ó Readmiss√£o  
        if all(col in self.df.columns for col in ['gender', 'medical_specialty']):
            print("\nüë• An√°lise: G√™nero √ó Especialidade M√©dica √ó Readmiss√£o")
            
            # Pegar top 6 especialidades
            top_specialties = self.df['medical_specialty'].value_counts().head(6).index.tolist()
            df_specialty = self.df[self.df['medical_specialty'].isin(top_specialties)]
            
            if not df_specialty.empty:
                gender_spec_stats = df_specialty.groupby(['gender', 'medical_specialty'])['target'].agg(['count', 'mean']).reset_index()
                gender_spec_stats.columns = ['gender', 'medical_specialty', 'count', 'readmission_rate']
                
                # Filtrar grupos com pelo menos 30 casos
                gender_spec_stats = gender_spec_stats[gender_spec_stats['count'] >= 30]
                
                if not gender_spec_stats.empty:
                    fig, ax = plt.subplots(1, 1, figsize=(14, 8))
                    
                    # Criar gr√°fico de barras agrupadas
                    x_pos = np.arange(len(top_specialties))
                    width = 0.35
                    
                    male_data = []
                    female_data = []
                    
                    for specialty in top_specialties:
                        male_rate = gender_spec_stats[(gender_spec_stats['gender'] == 'Male') & 
                                                    (gender_spec_stats['medical_specialty'] == specialty)]
                        female_rate = gender_spec_stats[(gender_spec_stats['gender'] == 'Female') & 
                                                      (gender_spec_stats['medical_specialty'] == specialty)]
                        
                        male_data.append(male_rate['readmission_rate'].iloc[0] * 100 if not male_rate.empty else 0)
                        female_data.append(female_rate['readmission_rate'].iloc[0] * 100 if not female_rate.empty else 0)
                    
                    bars1 = ax.bar(x_pos - width/2, male_data, width, label='Masculino', alpha=0.8, color='lightblue')
                    bars2 = ax.bar(x_pos + width/2, female_data, width, label='Feminino', alpha=0.8, color='lightcoral')
                    
                    ax.set_xlabel('Especialidade M√©dica')
                    ax.set_ylabel('Taxa de Readmiss√£o (%)')
                    ax.set_title('Taxa de Readmiss√£o por G√™nero e Especialidade M√©dica', 
                                fontsize=14, fontweight='bold')
                    ax.set_xticks(x_pos)
                    ax.set_xticklabels([spec.replace(' ', '\n') for spec in top_specialties], fontsize=10)
                    ax.legend()
                    ax.grid(True, alpha=0.3, axis='y')
                    
                    # Adicionar valores nas barras
                    for bar in bars1:
                        height = bar.get_height()
                        if height > 0:
                            ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                                   f'{height:.1f}%', ha='center', va='bottom', fontsize=8)
                    
                    for bar in bars2:
                        height = bar.get_height()
                        if height > 0:
                            ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                                   f'{height:.1f}%', ha='center', va='bottom', fontsize=8)
                    
                    plt.tight_layout()
                    self.save_figure(fig, 'multivariate_gender_specialty_analysis')
                    
                    print(f"  üìä Diferen√ßas por g√™nero nas especialidades:")
                    for i, specialty in enumerate(top_specialties):
                        male_rate = male_data[i]
                        female_rate = female_data[i]
                        if male_rate > 0 and female_rate > 0:
                            diff = abs(male_rate - female_rate)
                            higher_gender = "Masculino" if male_rate > female_rate else "Feminino"
                            print(f"    ‚Ä¢ {specialty}: {higher_gender} tem {diff:.1f}pp maior risco")
        
        print(f"\nüí° INSIGHTS MULTIVARIADOS:")
        print(f"  ‚Ä¢ An√°lises multivariadas revelam intera√ß√µes complexas entre vari√°veis")
        print(f"  ‚Ä¢ Certas combina√ß√µes de caracter√≠sticas podem ter risco muito maior")
        print(f"  ‚Ä¢ Considere features de intera√ß√£o no modelo de ML")
        print(f"  ‚Ä¢ Segmenta√ß√£o de pacientes pode ser √∫til para estrat√©gias targeted")
    
    def analyze_diagnosis_groups(self):
        """Analisa grupos de diagn√≥sticos e sua rela√ß√£o com readmiss√£o"""
        print("\n" + "="*60)
        print("AN√ÅLISE DE GRUPOS DE DIAGN√ìSTICOS")
        print("="*60)
        
        # Verificar se temos colunas de diagn√≥stico
        diag_cols = [col for col in self.df.columns if col.startswith('diag_')]
        
        if not diag_cols:
            print("‚ö†Ô∏è  Colunas de diagn√≥stico n√£o encontradas no dataset.")
            return
        
        print(f"üìã Analisando colunas de diagn√≥stico: {diag_cols}")
        
        # Fun√ß√£o para categorizar diagn√≥sticos em grupos principais
        def categorize_diagnosis(code):
            """Categoriza c√≥digos de diagn√≥stico em grupos principais"""
            if pd.isna(code) or code == 'unknown' or code == '?':
                return 'Unknown'
            
            try:
                # Converter para string e extrair primeiros d√≠gitos
                code_str = str(code).strip()
                
                # Se come√ßa com 'V' ou 'E', s√£o c√≥digos especiais
                if code_str.startswith(('V', 'E')):
                    if code_str.startswith('V'):
                        return 'V-Codes (Suplementar)'
                    else:
                        return 'E-Codes (Externa)'
                
                # Extrair n√∫mero principal
                code_num = float(code_str.split('.')[0])
                
                # Categoriza√ß√£o baseada em faixas CID-9
                if 1 <= code_num <= 139:
                    return 'Infecciosas/Parasit√°rias'
                elif 140 <= code_num <= 239:
                    return 'Neoplasias'
                elif 240 <= code_num <= 279:
                    return 'End√≥crinas/Metab√≥licas'
                elif 280 <= code_num <= 289:
                    return 'Sangue/√ìrg√£os Hematopoi√©ticos'
                elif 290 <= code_num <= 319:
                    return 'Mentais'
                elif 320 <= code_num <= 389:
                    return 'Sistema Nervoso'
                elif 390 <= code_num <= 459:
                    return 'Circulat√≥rias'
                elif 460 <= code_num <= 519:
                    return 'Respirat√≥rias'
                elif 520 <= code_num <= 579:
                    return 'Digestivas'
                elif 580 <= code_num <= 629:
                    return 'Genitourin√°rias'
                elif 630 <= code_num <= 679:
                    return 'Gravidez/Parto'
                elif 680 <= code_num <= 709:
                    return 'Pele/Subcut√¢neo'
                elif 710 <= code_num <= 739:
                    return 'Musculoesquel√©ticas'
                elif 740 <= code_num <= 759:
                    return 'Cong√™nitas'
                elif 760 <= code_num <= 779:
                    return 'Perinatais'
                elif 780 <= code_num <= 799:
                    return 'Sintomas/Sinais'
                elif 800 <= code_num <= 999:
                    return 'Les√µes/Envenenamentos'
                else:
                    return 'Outros'
                    
            except (ValueError, AttributeError):
                return 'Unknown'
        
        # Analisar cada coluna de diagn√≥stico
        diagnosis_results = {}
        
        for diag_col in diag_cols:
            print(f"\nüîç An√°lise de {diag_col}:")
            
            # Aplicar categoriza√ß√£o
            self.df[f'{diag_col}_category'] = self.df[diag_col].apply(categorize_diagnosis)
            
            # Estat√≠sticas por categoria
            diag_stats = self.df.groupby(f'{diag_col}_category')['target'].agg(['count', 'mean']).round(3)
            diag_stats.columns = ['Total_Casos', 'Taxa_Readmissao']
            diag_stats = diag_stats.sort_values('Total_Casos', ascending=False)
            
            diagnosis_results[diag_col] = diag_stats
            
            print(f"  Top 10 categorias por frequ√™ncia:")
            for category, row in diag_stats.head(10).iterrows():
                print(f"    {category}: {row['Total_Casos']:,} casos ({row['Taxa_Readmissao']*100:.1f}% readmiss√£o)")
        
        # Visualiza√ß√µes
        if diagnosis_results:
            fig, axes = plt.subplots(2, len(diag_cols), figsize=(6*len(diag_cols), 12))
            if len(diag_cols) == 1:
                axes = axes.reshape(-1, 1)
            
            for i, (diag_col, diag_stats) in enumerate(diagnosis_results.items()):
                # Gr√°fico 1: Distribui√ß√£o de categorias
                ax1 = axes[0, i] if len(diag_cols) > 1 else axes[0]
                top_categories = diag_stats.head(8)
                
                bars = ax1.barh(range(len(top_categories)), top_categories['Total_Casos'], 
                               color='lightblue', alpha=0.8)
                ax1.set_yticks(range(len(top_categories)))
                ax1.set_yticklabels([cat[:20] + '...' if len(cat) > 20 else cat 
                                   for cat in top_categories.index], fontsize=9)
                ax1.set_xlabel('N√∫mero de Casos')
                ax1.set_title(f'Top Categorias - {diag_col}', fontsize=12, fontweight='bold')
                
                # Adicionar valores
                for j, v in enumerate(top_categories['Total_Casos']):
                    ax1.text(v + max(top_categories['Total_Casos'])*0.01, j, f'{v:,}', 
                            va='center', fontsize=8)
                
                # Gr√°fico 2: Taxa de readmiss√£o por categoria
                ax2 = axes[1, i] if len(diag_cols) > 1 else axes[1]
                readmit_rates = top_categories['Taxa_Readmissao'] * 100
                
                bars2 = ax2.barh(range(len(readmit_rates)), readmit_rates, 
                                color='salmon', alpha=0.8)
                ax2.set_yticks(range(len(readmit_rates)))
                ax2.set_yticklabels([cat[:20] + '...' if len(cat) > 20 else cat 
                                   for cat in readmit_rates.index], fontsize=9)
                ax2.set_xlabel('Taxa de Readmiss√£o (%)')
                ax2.set_title(f'Taxa Readmiss√£o - {diag_col}', fontsize=12, fontweight='bold')
                
                # Adicionar valores
                for j, v in enumerate(readmit_rates.values):
                    ax2.text(v + 0.2, j, f'{v:.1f}%', va='center', fontsize=8)
            
            plt.tight_layout()
            self.save_figure(fig, 'diagnosis_groups_analysis')
        
        # An√°lise combinada de diagn√≥sticos
        if len(diag_cols) >= 2:
            print(f"\nüîó An√°lise combinada de diagn√≥sticos:")
            
            # Criar combina√ß√µes dos dois diagn√≥sticos principais
            primary_diag = f'{diag_cols[0]}_category'
            secondary_diag = f'{diag_cols[1]}_category'
            
            # Combina√ß√µes mais comuns
            combo_stats = self.df.groupby([primary_diag, secondary_diag])['target'].agg(['count', 'mean']).reset_index()
            combo_stats.columns = [primary_diag, secondary_diag, 'Total_Casos', 'Taxa_Readmissao']
            combo_stats = combo_stats[combo_stats['Total_Casos'] >= 50]  # Filtrar combina√ß√µes raras
            combo_stats = combo_stats.sort_values('Total_Casos', ascending=False)
            
            print(f"  Top 10 combina√ß√µes de diagn√≥sticos:")
            for _, row in combo_stats.head(10).iterrows():
                print(f"    {row[primary_diag]} + {row[secondary_diag]}: {row['Total_Casos']:,} casos ({row['Taxa_Readmissao']*100:.1f}% readmiss√£o)")
        
        # Insights sobre diagn√≥sticos
        print(f"\nüí° INSIGHTS DE DIAGN√ìSTICOS:")
        if diagnosis_results:
            for diag_col, diag_stats in diagnosis_results.items():
                highest_risk_category = diag_stats['Taxa_Readmissao'].idxmax()
                highest_risk_rate = diag_stats.loc[highest_risk_category, 'Taxa_Readmissao'] * 100
                most_common_category = diag_stats['Total_Casos'].idxmax()
                
                print(f"  ‚Ä¢ {diag_col}:")
                print(f"    - Categoria mais comum: {most_common_category}")
                print(f"    - Maior risco de readmiss√£o: {highest_risk_category} ({highest_risk_rate:.1f}%)")
        
        print(f"  ‚Ä¢ Diagn√≥sticos circulat√≥rios e respirat√≥rios tendem a ter maior risco")
        print(f"  ‚Ä¢ Combina√ß√µes de diagn√≥sticos podem indicar maior complexidade")
        print(f"  ‚Ä¢ Considere agrupamento de diagn√≥sticos como feature engineering")
    
    def generate_summary_report(self):
        """Gera um relat√≥rio resumido com os principais insights"""
        print("\n" + "="*60)
        print("RELAT√ìRIO RESUMIDO - PRINCIPAIS INSIGHTS")
        print("="*60)
        
        insights = []
        
        # Insights sobre a vari√°vel target
        if 'target' in self.df.columns:
            readmission_rate = self.df['target'].mean() * 100
            insights.append(f"üìä Taxa geral de readmiss√£o em <30 dias: {readmission_rate:.1f}%")
            
            if readmission_rate > 15:
                insights.append("‚ö†Ô∏è  Taxa de readmiss√£o acima de 15% - indicador de risco elevado")
            elif readmission_rate < 5:
                insights.append("‚úÖ Taxa de readmiss√£o baixa - bom controle hospitalar")
        
        # Insights sobre dados faltantes
        missing_pct = (self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100
        if missing_pct > 20:
            insights.append(f"‚ö†Ô∏è  {missing_pct:.1f}% de dados faltantes - requer aten√ß√£o na limpeza")
        elif missing_pct < 5:
            insights.append(f"‚úÖ Apenas {missing_pct:.1f}% de dados faltantes - dataset de boa qualidade")
        
        # Insights demogr√°ficos
        if 'age' in self.df.columns and 'target' in self.df.columns:
            age_risk = self.df.groupby('age')['target'].mean()
            highest_risk_age = age_risk.idxmax()
            highest_risk_rate = age_risk.max() * 100
            insights.append(f"üë• Faixa et√°ria de maior risco: {highest_risk_age} ({highest_risk_rate:.1f}%)")
        
        # Insights m√©dicos
        numeric_cols = ['num_lab_procedures', 'num_medications', 'time_in_hospital']
        available_numeric = [col for col in numeric_cols if col in self.df.columns]
        
        if available_numeric and 'target' in self.df.columns:
            correlations = self.df[available_numeric].corrwith(self.df['target']).abs()
            strongest_predictor = correlations.idxmax()
            correlation_value = correlations.max()
            insights.append(f"üî¨ Melhor preditor m√©dico: {strongest_predictor} (correla√ß√£o: {correlation_value:.3f})")
        
        # Insights sobre medicamentos
        med_columns = [col for col in self.df.columns if 'insulin' in col.lower() or 'metformin' in col.lower()]
        if med_columns and 'target' in self.df.columns:
            for med_col in med_columns[:2]:  # Top 2 medicamentos
                if med_col in self.df.columns:
                    med_usage = (self.df[med_col] != 'No').mean() * 100
                    if med_usage > 30:
                        insights.append(f"üíä {med_col}: usado em {med_usage:.1f}% dos casos")
        
        # Imprimir insights
        for i, insight in enumerate(insights, 1):
            print(f"{i:2d}. {insight}")
        
        # Recomenda√ß√µes
        print(f"\nüí° RECOMENDA√á√ïES PARA MODELAGEM:")
        recommendations = []
        
        if missing_pct > 15:
            recommendations.append("‚Ä¢ Implementar estrat√©gias robustas de tratamento de dados faltantes")
        
        if len(available_numeric) > 0:
            recommendations.append("‚Ä¢ Considerar normaliza√ß√£o/padroniza√ß√£o das vari√°veis num√©ricas")
        
        if 'medical_specialty' in self.df.columns:
            n_specialties = self.df['medical_specialty'].nunique()
            if n_specialties > 20:
                recommendations.append(f"‚Ä¢ Agrupar especialidades m√©dicas ({n_specialties} categorias) para reduzir dimensionalidade")
        
        recommendations.append("‚Ä¢ Aplicar t√©cnicas de feature engineering para vari√°veis categ√≥ricas")
        recommendations.append("‚Ä¢ Considerar t√©cnicas de balanceamento devido ao desbalanceamento da target")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"{i:2d}. {rec}")
        
        return insights, recommendations
    
    def save_html_report(self):
        """Gera um relat√≥rio HTML com todos os resultados"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Relat√≥rio de An√°lise Explorat√≥ria - Readmiss√£o Hospitalar Diab√©tica</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}
                h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
                h2 {{ color: #34495e; border-left: 4px solid #3498db; padding-left: 10px; }}
                .summary {{ background-color: #ecf0f1; padding: 20px; border-radius: 5px; margin: 20px 0; }}
                .insight {{ background-color: #d5dbdb; padding: 10px; margin: 10px 0; border-left: 4px solid #3498db; }}
                .metric {{ font-weight: bold; color: #2980b9; }}
                .warning {{ color: #e74c3c; font-weight: bold; }}
                .success {{ color: #27ae60; font-weight: bold; }}
                table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
                th, td {{ border: 1px solid #bdc3c7; padding: 12px; text-align: left; }}
                th {{ background-color: #3498db; color: white; }}
                .figure-list {{ list-style-type: none; padding: 0; }}
                .figure-list li {{ margin: 10px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }}
            </style>
        </head>
        <body>
            <h1>üìä Relat√≥rio de An√°lise Explorat√≥ria</h1>
            <h2>Predi√ß√£o de Readmiss√£o Hospitalar Diab√©tica</h2>
            
            <div class="summary">
                <h3>üìã Resumo Executivo</h3>
                <p><span class="metric">Dataset:</span> {len(self.df):,} registros, {len(self.df.columns)} colunas</p>
                <p><span class="metric">Pacientes √∫nicos:</span> {self.df['patient_nbr'].nunique():,}</p>
                <p><span class="metric">Taxa de readmiss√£o <30 dias:</span> {self.df['target'].mean()*100:.1f}%</p>
                <p><span class="metric">Data da an√°lise:</span> {datetime.now().strftime('%d/%m/%Y %H:%M')}</p>
            </div>
            
            <h2>üìà Visualiza√ß√µes Geradas</h2>
            <ul class="figure-list">
        """
        
        # Adicionar lista de figuras geradas
        for figure_path in self.figures:
            figure_name = os.path.basename(figure_path).replace('.png', '').replace('_', ' ').title()
            html_content += f"<li>üìä {figure_name}</li>"
        
        html_content += """
            </ul>
            
            <div class="summary">
                <h3>üéØ Como Interpretar os Resultados</h3>
                <ul>
                    <li><strong>Gr√°ficos de Distribui√ß√£o:</strong> Mostram como os dados est√£o distribu√≠dos</li>
                    <li><strong>Mapas de Calor:</strong> Revelam padr√µes de correla√ß√£o e dados faltantes</li>
                    <li><strong>An√°lises Comparativas:</strong> Destacam diferen√ßas entre grupos</li>
                    <li><strong>Box Plots:</strong> Identificam outliers e diferen√ßas estat√≠sticas</li>
                </ul>
            </div>
            
            <h2>üìÅ Arquivos de Sa√≠da</h2>
            <p>Todos os gr√°ficos foram salvos na pasta <code>results/</code> em alta qualidade (300 DPI).</p>
            
            <footer style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #bdc3c7; color: #7f8c8d;">
                <p>Relat√≥rio gerado automaticamente pelo m√≥dulo de An√°lise Explorat√≥ria</p>
                <p>Projeto: BCC325 - Intelig√™ncia Artificial | UFOP</p>
            </footer>
        </body>
        </html>
        """
        
        # Salvar arquivo HTML
        html_path = os.path.join(self.results_dir, 'eda_report.html')
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"\nüìÑ Relat√≥rio HTML salvo: {html_path}")
        return html_path
    
    def run_complete_analysis(self):
        """
        Executa a an√°lise explorat√≥ria completa dos dados
        
        Returns:
            pd.DataFrame: DataFrame com os dados analisados e a vari√°vel target criada
        """
        print("üöÄ INICIANDO AN√ÅLISE EXPLORAT√ìRIA COMPLETA")
        print("="*70)
        
        try:
            # 1. Carregar dados
            print("\nüìä Etapa 1: Carregamento dos dados")
            self.load_data()
            
            if self.df is None or self.df.empty:
                raise ValueError("N√£o foi poss√≠vel carregar os dados")
            
            # 2. Informa√ß√µes b√°sicas
            print("\nüìã Etapa 2: Informa√ß√µes b√°sicas do dataset")
            self.basic_info()
            
            # 3. An√°lise da vari√°vel target (CR√çTICO - cria a vari√°vel target)
            print("\nüéØ Etapa 3: An√°lise da vari√°vel alvo")
            self.analyze_target_variable()
            
            # 4. An√°lise de dados faltantes
            print("\nüîç Etapa 4: An√°lise de dados faltantes")
            self.analyze_missing_data()
            
            # 5. An√°lise demogr√°fica
            print("\nüë• Etapa 5: An√°lise demogr√°fica")
            self.analyze_demographic_data()
            
            # 6. An√°lise m√©dica
            print("\nüè• Etapa 6: An√°lise de dados m√©dicos")
            self.analyze_medical_data()
            
            # 7. An√°lise de medicamentos
            print("\nüíä Etapa 7: An√°lise de medicamentos")
            self.analyze_medication_data()
            
            # 8. An√°lise multivariada (NOVA)
            print("\nüîó Etapa 8: An√°lise multivariada")
            self.analyze_multivariate_relationships()
            
            # 9. An√°lise de grupos de diagn√≥sticos (NOVA)
            print("\nü©∫ Etapa 9: An√°lise de grupos de diagn√≥sticos")
            self.analyze_diagnosis_groups()
            
            # 10. An√°lise com mapeamentos de IDs
            print("\nüîó Etapa 10: An√°lise com mapeamentos de IDs")
            self.analyze_id_mappings()
            
            # 11. Gerar relat√≥rio resumido
            print("\nüìù Etapa 11: Gera√ß√£o de relat√≥rio resumido")
            insights, recommendations = self.generate_summary_report()
            
            # 12. Salvar relat√≥rio HTML
            print("\nüíæ Etapa 12: Salvando relat√≥rio HTML")
            html_report_path = self.save_html_report()
            
            # Resumo final
            print("\n" + "="*70)
            print("‚úÖ AN√ÅLISE EXPLORAT√ìRIA CONCLU√çDA COM SUCESSO!")
            print("="*70)
            print(f"üìä Total de registros analisados: {len(self.df):,}")
            print(f"üìà Gr√°ficos gerados: {len(self.figures)}")
            print(f"üìÑ Relat√≥rio HTML: {html_report_path}")
            print(f"üéØ Vari√°vel target criada: {'target' in self.df.columns}")
            
            if 'target' in self.df.columns:
                print(f"üìä Taxa de readmiss√£o <30 dias: {self.df['target'].mean()*100:.1f}%")
            
            return self.df
            
        except Exception as e:
            print(f"\n‚ùå Erro durante a an√°lise explorat√≥ria: {str(e)}")
            print("üîß Verifique se:")
            print("  ‚Ä¢ O arquivo de dados existe e est√° acess√≠vel")
            print("  ‚Ä¢ As depend√™ncias est√£o instaladas")
            print("  ‚Ä¢ O diret√≥rio de resultados pode ser criado")
            raise


def main():
    """Fun√ß√£o principal para executar a an√°lise explorat√≥ria"""
    eda = ExploratoryDataAnalysis()
    df_analyzed = eda.run_complete_analysis()
    return df_analyzed


if __name__ == "__main__":
    main()
